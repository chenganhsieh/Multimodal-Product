2023/11/01 16:22:03 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 1580099020
    GPU 0,1,2,3,4,5: NVIDIA GeForce RTX 4090
    CUDA_HOME: /usr/local/cuda-11.3
    NVCC: Cuda compilation tools, release 11.3, V11.3.58
    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
    PyTorch: 1.10.2
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

    TorchVision: 0.11.3
    OpenCV: 4.8.1
    MMEngine: 0.9.0

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1580099020
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2023/11/01 16:22:03 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=1024)
cute80_textrecog_data_root = 'data/cute80'
cute80_textrecog_test = dict(
    ann_file='textrecog_test.json',
    data_root='data/cute80',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    sync_buffer=dict(type='SyncBuffersHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(
        draw_gt=False,
        draw_pred=False,
        enable=False,
        interval=1,
        show=False,
        type='VisualizationHook'))
default_scope = 'mmocr'
dictionary = dict(
    dict_file=
    '/home/biometrics/reserve/Multimodal-Product/implement_prev/configs/textrecog/aster/../../../dicts/english_digits_symbols.txt',
    same_start_end=True,
    type='Dictionary',
    with_end=True,
    with_padding=True,
    with_start=True,
    with_unknown=True)
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
icdar2013_857_textrecog_test = dict(
    ann_file='textrecog_test_857.json',
    data_root='data/icdar2013',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
icdar2013_textrecog_data_root = 'data/icdar2013'
icdar2013_textrecog_test = dict(
    ann_file='textrecog_test.json',
    data_root='data/icdar2013',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
icdar2013_textrecog_train = dict(
    ann_file='textrecog_train.json',
    data_root='data/icdar2013',
    pipeline=None,
    type='OCRDataset')
icdar2015_1811_textrecog_test = dict(
    ann_file='textrecog_test_1811.json',
    data_root='data/icdar2015',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
icdar2015_textrecog_data_root = 'data/icdar2015'
icdar2015_textrecog_test = dict(
    ann_file='textrecog_test.json',
    data_root='data/icdar2015',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
icdar2015_textrecog_train = dict(
    ann_file='textrecog_train.json',
    data_root='data/icdar2015',
    pipeline=None,
    type='OCRDataset')
iiit5k_textrecog_data_root = 'data/iiit5k'
iiit5k_textrecog_test = dict(
    ann_file='textrecog_test.json',
    data_root='data/iiit5k',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
iiit5k_textrecog_train = dict(
    ann_file='textrecog_train.json',
    data_root='data/iiit5k',
    pipeline=None,
    type='OCRDataset')
launcher = 'none'
load_from = 'checkpoints/textrecog/aster_resnet45_6e_st_mj-cc56eca4.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)
mjsynth_sub_textrecog_train = dict(
    ann_file='subset_textrecog_train.json',
    data_root='data/mjsynth',
    pipeline=None,
    type='OCRDataset')
mjsynth_textrecog_data_root = 'data/mjsynth'
mjsynth_textrecog_train = dict(
    ann_file='textrecog_train.json',
    data_root='data/mjsynth',
    pipeline=None,
    type='OCRDataset')
model = dict(
    backbone=dict(
        arch_channels=[
            32,
            64,
            128,
            256,
            512,
        ],
        arch_layers=[
            3,
            4,
            6,
            6,
            3,
        ],
        block_cfgs=dict(type='BasicBlock', use_conv1x1='True'),
        in_channels=3,
        init_cfg=[
            dict(layer='Conv2d', type='Kaiming'),
            dict(layer='BatchNorm2d', type='Constant', val=1),
        ],
        stem_channels=[
            32,
        ],
        strides=[
            (
                2,
                2,
            ),
            (
                2,
                2,
            ),
            (
                2,
                1,
            ),
            (
                2,
                1,
            ),
            (
                2,
                1,
            ),
        ],
        type='ResNet'),
    data_preprocessor=dict(
        mean=[
            127.5,
            127.5,
            127.5,
        ],
        std=[
            127.5,
            127.5,
            127.5,
        ],
        type='TextRecogDataPreprocessor'),
    decoder=dict(
        attn_dims=512,
        dictionary=dict(
            dict_file=
            '/home/biometrics/reserve/Multimodal-Product/implement_prev/configs/textrecog/aster/../../../dicts/english_digits_symbols.txt',
            same_start_end=True,
            type='Dictionary',
            with_end=True,
            with_padding=True,
            with_start=True,
            with_unknown=True),
        emb_dims=512,
        hidden_size=512,
        in_channels=512,
        max_seq_len=25,
        module_loss=dict(
            flatten=True, ignore_first_char=True, type='CEModuleLoss'),
        postprocessor=dict(type='AttentionPostprocessor'),
        type='ASTERDecoder'),
    encoder=dict(in_channels=512, type='ASTEREncoder'),
    preprocessor=dict(
        in_channels=3,
        num_control_points=20,
        output_image_size=(
            32,
            100,
        ),
        resized_image_size=(
            32,
            64,
        ),
        type='STN'),
    type='ASTER')
optim_wrapper = dict(
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0004,
        type='AdamW',
        weight_decay=0.05),
    type='OptimWrapper')
param_scheduler = [
    dict(
        T_max=6,
        convert_to_iter_based=True,
        eta_min=4e-06,
        type='CosineAnnealingLR'),
]
randomness = dict(seed=None)
resume = False
svt_textrecog_data_root = 'data/svt'
svt_textrecog_test = dict(
    ann_file='textrecog_test.json',
    data_root='data/svt',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
svt_textrecog_train = dict(
    ann_file='textrecog_train.json',
    data_root='data/svt',
    pipeline=None,
    type='OCRDataset')
svtp_textrecog_data_root = 'data/svtp'
svtp_textrecog_test = dict(
    ann_file='textrecog_test.json',
    data_root='data/svtp',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
svtp_textrecog_train = dict(
    ann_file='textrecog_train.json',
    data_root='data/svtp',
    pipeline=None,
    type='OCRDataset')
synthtext_an_textrecog_train = dict(
    ann_file='alphanumeric_textrecog_train.json',
    data_root='data/synthtext',
    pipeline=None,
    type='OCRDataset')
synthtext_sub_textrecog_train = dict(
    ann_file='subset_textrecog_train.json',
    data_root='data/synthtext',
    pipeline=None,
    type='OCRDataset')
synthtext_textrecog_data_root = 'data/synthtext'
synthtext_textrecog_train = dict(
    ann_file='textrecog_train.json',
    data_root='data/synthtext',
    pipeline=None,
    type='OCRDataset')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        datasets=[
            dict(
                ann_file='textrecog_test.json',
                data_root='data/icdar2015',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(scale=(
                256,
                64,
            ), type='Resize'),
            dict(type='LoadOCRAnnotations', with_text=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'valid_ratio',
                    'instances',
                ),
                type='PackTextRecogInputs'),
        ],
        type='ConcatDataset'),
    drop_last=False,
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_dataset = dict(
    datasets=[
        dict(
            ann_file='textrecog_test.json',
            data_root='data/icdar2015',
            pipeline=None,
            test_mode=True,
            type='OCRDataset'),
    ],
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(scale=(
            256,
            64,
        ), type='Resize'),
        dict(type='LoadOCRAnnotations', with_text=True),
        dict(
            meta_keys=(
                'img_path',
                'ori_shape',
                'img_shape',
                'valid_ratio',
                'instances',
            ),
            type='PackTextRecogInputs'),
    ],
    type='ConcatDataset')
test_evaluator = dict(
    dataset_prefixes=[
        'IC15',
    ],
    metrics=[
        dict(
            mode=[
                'exact',
                'ignore_case',
                'ignore_case_symbol',
            ],
            type='WordMetric'),
        dict(type='CharMetric'),
    ],
    type='MultiDatasetsEvaluator')
test_list = [
    dict(
        ann_file='textrecog_test.json',
        data_root='data/icdar2015',
        pipeline=None,
        test_mode=True,
        type='OCRDataset'),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(scale=(
        256,
        64,
    ), type='Resize'),
    dict(type='LoadOCRAnnotations', with_text=True),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
            'valid_ratio',
            'instances',
        ),
        type='PackTextRecogInputs'),
]
train_cfg = dict(max_epochs=6, type='EpochBasedTrainLoop', val_interval=1)
train_dataloader = dict(
    batch_size=1024,
    dataset=dict(
        datasets=[
            dict(
                ann_file='textrecog_train.json',
                data_root='data/mjsynth',
                pipeline=None,
                type='OCRDataset'),
            dict(
                ann_file='textrecog_train.json',
                data_root='data/synthtext',
                pipeline=None,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(ignore_empty=True, min_size=5, type='LoadImageFromFile'),
            dict(type='LoadOCRAnnotations', with_text=True),
            dict(scale=(
                256,
                64,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'valid_ratio',
                ),
                type='PackTextRecogInputs'),
        ],
        type='ConcatDataset'),
    num_workers=24,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_dataset = dict(
    datasets=[
        dict(
            ann_file='textrecog_train.json',
            data_root='data/mjsynth',
            pipeline=None,
            type='OCRDataset'),
        dict(
            ann_file='textrecog_train.json',
            data_root='data/synthtext',
            pipeline=None,
            type='OCRDataset'),
    ],
    pipeline=[
        dict(ignore_empty=True, min_size=5, type='LoadImageFromFile'),
        dict(type='LoadOCRAnnotations', with_text=True),
        dict(scale=(
            256,
            64,
        ), type='Resize'),
        dict(
            meta_keys=(
                'img_path',
                'ori_shape',
                'img_shape',
                'valid_ratio',
            ),
            type='PackTextRecogInputs'),
    ],
    type='ConcatDataset')
train_list = [
    dict(
        ann_file='textrecog_train.json',
        data_root='data/mjsynth',
        pipeline=None,
        type='OCRDataset'),
    dict(
        ann_file='textrecog_train.json',
        data_root='data/synthtext',
        pipeline=None,
        type='OCRDataset'),
]
train_pipeline = [
    dict(ignore_empty=True, min_size=5, type='LoadImageFromFile'),
    dict(type='LoadOCRAnnotations', with_text=True),
    dict(scale=(
        256,
        64,
    ), type='Resize'),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
            'valid_ratio',
        ),
        type='PackTextRecogInputs'),
]
tta_model = dict(type='EncoderDecoderRecognizerTTAModel')
tta_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(
                    condition="results['img_shape'][1]<results['img_shape'][0]",
                    true_transforms=[
                        dict(
                            args=[
                                dict(cls='Rot90', k=0, keep_size=False),
                            ],
                            type='ImgAugWrapper'),
                    ],
                    type='ConditionApply'),
                dict(
                    condition="results['img_shape'][1]<results['img_shape'][0]",
                    true_transforms=[
                        dict(
                            args=[
                                dict(cls='Rot90', k=1, keep_size=False),
                            ],
                            type='ImgAugWrapper'),
                    ],
                    type='ConditionApply'),
                dict(
                    condition="results['img_shape'][1]<results['img_shape'][0]",
                    true_transforms=[
                        dict(
                            args=[
                                dict(cls='Rot90', k=3, keep_size=False),
                            ],
                            type='ImgAugWrapper'),
                    ],
                    type='ConditionApply'),
            ],
            [
                dict(scale=(
                    256,
                    64,
                ), type='Resize'),
            ],
            [
                dict(type='LoadOCRAnnotations', with_text=True),
            ],
            [
                dict(
                    meta_keys=(
                        'img_path',
                        'ori_shape',
                        'img_shape',
                        'valid_ratio',
                        'instances',
                    ),
                    type='PackTextRecogInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        datasets=[
            dict(
                ann_file='textrecog_test.json',
                data_root='data/icdar2015',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(scale=(
                256,
                64,
            ), type='Resize'),
            dict(type='LoadOCRAnnotations', with_text=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'valid_ratio',
                    'instances',
                ),
                type='PackTextRecogInputs'),
        ],
        type='ConcatDataset'),
    drop_last=False,
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    dataset_prefixes=[
        'IC15',
    ],
    metrics=[
        dict(
            mode=[
                'exact',
                'ignore_case',
                'ignore_case_symbol',
            ],
            type='WordMetric'),
        dict(type='CharMetric'),
    ],
    type='MultiDatasetsEvaluator')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='TextRecogLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/aster_resnet45_6e_st_mj'

2023/11/01 16:22:07 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2023/11/01 16:22:07 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/11/01 16:22:08 - mmengine - INFO - Load checkpoint from checkpoints/textrecog/aster_resnet45_6e_st_mj-cc56eca4.pth
2023/11/01 16:22:10 - mmengine - INFO - Epoch(test) [  50/2077]    eta: 0:01:05  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:11 - mmengine - INFO - Epoch(test) [ 100/2077]    eta: 0:00:45  time: 0.0140  data_time: 0.0001  memory: 94  
2023/11/01 16:22:11 - mmengine - INFO - Epoch(test) [ 150/2077]    eta: 0:00:38  time: 0.0151  data_time: 0.0001  memory: 94  
2023/11/01 16:22:12 - mmengine - INFO - Epoch(test) [ 200/2077]    eta: 0:00:34  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:13 - mmengine - INFO - Epoch(test) [ 250/2077]    eta: 0:00:31  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:13 - mmengine - INFO - Epoch(test) [ 300/2077]    eta: 0:00:29  time: 0.0148  data_time: 0.0001  memory: 94  
2023/11/01 16:22:14 - mmengine - INFO - Epoch(test) [ 350/2077]    eta: 0:00:28  time: 0.0155  data_time: 0.0001  memory: 94  
2023/11/01 16:22:15 - mmengine - INFO - Epoch(test) [ 400/2077]    eta: 0:00:27  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:15 - mmengine - INFO - Epoch(test) [ 450/2077]    eta: 0:00:25  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:16 - mmengine - INFO - Epoch(test) [ 500/2077]    eta: 0:00:24  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:17 - mmengine - INFO - Epoch(test) [ 550/2077]    eta: 0:00:23  time: 0.0155  data_time: 0.0001  memory: 94  
2023/11/01 16:22:17 - mmengine - INFO - Epoch(test) [ 600/2077]    eta: 0:00:22  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:18 - mmengine - INFO - Epoch(test) [ 650/2077]    eta: 0:00:21  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:19 - mmengine - INFO - Epoch(test) [ 700/2077]    eta: 0:00:20  time: 0.0136  data_time: 0.0001  memory: 94  
2023/11/01 16:22:19 - mmengine - INFO - Epoch(test) [ 750/2077]    eta: 0:00:19  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:20 - mmengine - INFO - Epoch(test) [ 800/2077]    eta: 0:00:19  time: 0.0142  data_time: 0.0001  memory: 94  
2023/11/01 16:22:21 - mmengine - INFO - Epoch(test) [ 850/2077]    eta: 0:00:18  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:22 - mmengine - INFO - Epoch(test) [ 900/2077]    eta: 0:00:17  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:22 - mmengine - INFO - Epoch(test) [ 950/2077]    eta: 0:00:16  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:23 - mmengine - INFO - Epoch(test) [1000/2077]    eta: 0:00:15  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:24 - mmengine - INFO - Epoch(test) [1050/2077]    eta: 0:00:14  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:24 - mmengine - INFO - Epoch(test) [1100/2077]    eta: 0:00:14  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:25 - mmengine - INFO - Epoch(test) [1150/2077]    eta: 0:00:13  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:26 - mmengine - INFO - Epoch(test) [1200/2077]    eta: 0:00:12  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:26 - mmengine - INFO - Epoch(test) [1250/2077]    eta: 0:00:11  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:27 - mmengine - INFO - Epoch(test) [1300/2077]    eta: 0:00:11  time: 0.0133  data_time: 0.0001  memory: 94  
2023/11/01 16:22:28 - mmengine - INFO - Epoch(test) [1350/2077]    eta: 0:00:10  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:28 - mmengine - INFO - Epoch(test) [1400/2077]    eta: 0:00:09  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:29 - mmengine - INFO - Epoch(test) [1450/2077]    eta: 0:00:08  time: 0.0133  data_time: 0.0001  memory: 94  
2023/11/01 16:22:30 - mmengine - INFO - Epoch(test) [1500/2077]    eta: 0:00:08  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:30 - mmengine - INFO - Epoch(test) [1550/2077]    eta: 0:00:07  time: 0.0157  data_time: 0.0001  memory: 94  
2023/11/01 16:22:31 - mmengine - INFO - Epoch(test) [1600/2077]    eta: 0:00:06  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:32 - mmengine - INFO - Epoch(test) [1650/2077]    eta: 0:00:06  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:32 - mmengine - INFO - Epoch(test) [1700/2077]    eta: 0:00:05  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:33 - mmengine - INFO - Epoch(test) [1750/2077]    eta: 0:00:04  time: 0.0137  data_time: 0.0001  memory: 94  
2023/11/01 16:22:34 - mmengine - INFO - Epoch(test) [1800/2077]    eta: 0:00:03  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:35 - mmengine - INFO - Epoch(test) [1850/2077]    eta: 0:00:03  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:35 - mmengine - INFO - Epoch(test) [1900/2077]    eta: 0:00:02  time: 0.0136  data_time: 0.0001  memory: 94  
2023/11/01 16:22:36 - mmengine - INFO - Epoch(test) [1950/2077]    eta: 0:00:01  time: 0.0134  data_time: 0.0001  memory: 94  
2023/11/01 16:22:37 - mmengine - INFO - Epoch(test) [2000/2077]    eta: 0:00:01  time: 0.0141  data_time: 0.0001  memory: 94  
2023/11/01 16:22:37 - mmengine - INFO - Epoch(test) [2050/2077]    eta: 0:00:00  time: 0.0138  data_time: 0.0001  memory: 94  
2023/11/01 16:22:38 - mmengine - INFO - Epoch(test) [2077/2077]    IC15/recog/word_acc: 0.5267  IC15/recog/word_acc_ignore_case: 0.6842  IC15/recog/word_acc_ignore_case_symbol: 0.7140  IC15/recog/char_recall: 0.8781  IC15/recog/char_precision: 0.8971  data_time: 0.0005  time: 0.0141
