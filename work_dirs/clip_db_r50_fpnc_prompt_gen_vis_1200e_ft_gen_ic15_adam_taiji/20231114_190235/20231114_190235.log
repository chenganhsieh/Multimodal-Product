2023/11/14 19:02:38 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 1275828306
    GPU 0,1,2,3: NVIDIA GeForce RTX 4090
    CUDA_HOME: /usr/local/cuda-11.3
    NVCC: Cuda compilation tools, release 11.3, V11.3.58
    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
    PyTorch: 1.10.2
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

    TorchVision: 0.11.3
    OpenCV: 4.8.1
    MMEngine: 0.9.1

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1275828306
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 4
------------------------------------------------------------

2023/11/14 19:02:38 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16)
default_hooks = dict(
    checkpoint=dict(interval=5, max_keep_ckpts=1, type='CheckpointHook'),
    logger=dict(interval=5, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    sync_buffer=dict(type='SyncBuffersHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(
        draw_gt=False,
        draw_pred=False,
        enable=False,
        interval=1,
        show=False,
        type='VisualizationHook'))
default_scope = 'mmocr'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
icdar2015_textdet_data_root = 'data/icdar2015'
icdar2015_textdet_test = dict(
    ann_file='textdet_test.json',
    data_root='data/icdar2015',
    pipeline=[
        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
        dict(keep_ratio=True, scale=(
            4068,
            1024,
        ), type='Resize'),
        dict(
            type='LoadOCRAnnotations',
            with_bbox=True,
            with_label=True,
            with_polygon=True),
        dict(
            meta_keys=(
                'img_path',
                'ori_shape',
                'img_shape',
                'scale_factor',
            ),
            type='PackTextDetInputs'),
    ],
    test_mode=True,
    type='OCRDataset')
icdar2015_textdet_train = dict(
    ann_file='textdet_train.json',
    data_root='data/icdar2015',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=[
        dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
        dict(
            type='LoadOCRAnnotations',
            with_bbox=True,
            with_label=True,
            with_polygon=True),
        dict(
            brightness=0.12549019607843137,
            op='ColorJitter',
            saturation=0.5,
            type='TorchVisionWrapper'),
        dict(
            args=[
                [
                    'Fliplr',
                    0.5,
                ],
                dict(cls='Affine', rotate=[
                    -10,
                    10,
                ]),
                [
                    'Resize',
                    [
                        0.5,
                        3.0,
                    ],
                ],
            ],
            type='ImgAugWrapper'),
        dict(min_side_ratio=0.1, type='RandomCrop'),
        dict(keep_ratio=True, scale=(
            640,
            640,
        ), type='Resize'),
        dict(size=(
            640,
            640,
        ), type='Pad'),
        dict(
            meta_keys=(
                'img_path',
                'ori_shape',
                'img_shape',
            ),
            type='PackTextDetInputs'),
    ],
    type='OCRDataset')
launcher = 'pytorch'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)
model = dict(
    backbone=dict(
        input_resolution=640,
        layers=[
            3,
            4,
            6,
            3,
        ],
        output_dim=1024,
        style='pytorch',
        type='CLIPResNetWithAttention'),
    class_names=[
        'the pixels of many arbitrary-shape text instances.',
    ],
    context_decoder=dict(
        dropout=0.1,
        outdim=1024,
        style='pytorch',
        transformer_heads=4,
        transformer_layers=3,
        transformer_width=256,
        type='ContextDecoder',
        visual_dim=1024),
    context_length=14,
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='TextDetDataPreprocessor'),
    det_head=dict(
        in_channels=256,
        module_loss=dict(type='DBModuleLoss'),
        postprocessor=dict(text_repr_type='quad', type='DBPostprocessor'),
        type='DBHead'),
    identity_head=dict(
        bbce_loss=True,
        downsample_ratio=32.0,
        loss_weight=1.0,
        negative_ratio=3.0,
        reduction='mean',
        type='IdentityHead'),
    neck=dict(
        in_channels=[
            256,
            512,
            1024,
            2049,
        ],
        lateral_channels=256,
        type='FPNC'),
    pretrained='pretrained/RN50.pt',
    prompt_generator=dict(
        style='pytorch',
        token_embed_dim=512,
        type='PromptGenerator',
        visual_dim=1024),
    text_encoder=dict(
        context_length=18,
        embed_dim=1024,
        style='pytorch',
        transformer_heads=8,
        transformer_layers=12,
        transformer_width=512,
        type='CLIPTextContextEncoder'),
    type='CLIPProduct',
    use_learnable_prompt=True,
    use_learnable_prompt_only=False,
    visual_prompt_generator=dict(
        dropout=0.1,
        outdim=1024,
        style='pytorch',
        transformer_heads=4,
        transformer_layers=3,
        transformer_width=256,
        type='ContextDecoder',
        visual_dim=1024))
optim_wrapper = dict(
    optimizer=dict(lr=0.007, momentum=0.9, type='SGD', weight_decay=0.0001),
    type='OptimWrapper')
param_scheduler = [
    dict(begin=100, end=1200, eta_min=1e-07, power=0.9, type='PolyLR'),
]
prompt_class_names = [
    'the pixels of many arbitrary-shape text instances.',
]
randomness = dict(seed=None)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='textdet_test.json',
        data_root='data/icdar2015',
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                4068,
                1024,
            ), type='Resize'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackTextDetInputs'),
        ],
        test_mode=True,
        type='OCRDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(type='HmeanIOUMetric')
test_pipeline = [
    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        4068,
        1024,
    ), type='Resize'),
    dict(
        type='LoadOCRAnnotations',
        with_bbox=True,
        with_label=True,
        with_polygon=True),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackTextDetInputs'),
]
train_cfg = dict(max_epochs=1200, type='EpochBasedTrainLoop', val_interval=20)
train_dataloader = dict(
    batch_size=16,
    dataset=dict(
        ann_file='textdet_train.json',
        data_root='data/icdar2015',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                brightness=0.12549019607843137,
                op='ColorJitter',
                saturation=0.5,
                type='TorchVisionWrapper'),
            dict(
                args=[
                    [
                        'Fliplr',
                        0.5,
                    ],
                    dict(cls='Affine', rotate=[
                        -10,
                        10,
                    ]),
                    [
                        'Resize',
                        [
                            0.5,
                            3.0,
                        ],
                    ],
                ],
                type='ImgAugWrapper'),
            dict(min_side_ratio=0.1, type='RandomCrop'),
            dict(keep_ratio=True, scale=(
                640,
                640,
            ), type='Resize'),
            dict(size=(
                640,
                640,
            ), type='Pad'),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                ),
                type='PackTextDetInputs'),
        ],
        type='OCRDataset'),
    num_workers=24,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
    dict(
        type='LoadOCRAnnotations',
        with_bbox=True,
        with_label=True,
        with_polygon=True),
    dict(
        brightness=0.12549019607843137,
        op='ColorJitter',
        saturation=0.5,
        type='TorchVisionWrapper'),
    dict(
        args=[
            [
                'Fliplr',
                0.5,
            ],
            dict(cls='Affine', rotate=[
                -10,
                10,
            ]),
            [
                'Resize',
                [
                    0.5,
                    3.0,
                ],
            ],
        ],
        type='ImgAugWrapper'),
    dict(min_side_ratio=0.1, type='RandomCrop'),
    dict(keep_ratio=True, scale=(
        640,
        640,
    ), type='Resize'),
    dict(size=(
        640,
        640,
    ), type='Pad'),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
        ),
        type='PackTextDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='textdet_test.json',
        data_root='data/icdar2015',
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                4068,
                1024,
            ), type='Resize'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackTextDetInputs'),
        ],
        test_mode=True,
        type='OCRDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(type='HmeanIOUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='TextDetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji'

2023/11/14 19:02:39 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/11/14 19:02:40 - mmengine - INFO - Resize the pos_embed shape from torch.Size([50, 2048]) to torch.Size([401, 2048])
2023/11/14 19:02:40 - mmengine - INFO - [] [] are misaligned params in CLIPResNetWithAttention
2023/11/14 19:02:40 - mmengine - INFO - positional_embedding is tuncated from 77 to 18
2023/11/14 19:02:40 - mmengine - INFO - [] [] are misaligned params in text encoder
Name of parameter - Initialization information

contexts - torch.Size([1, 4, 512]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

gamma - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

vis_gamma - torch.Size([]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

backbone.conv1.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.bn1.weight - torch.Size([32]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.bn1.bias - torch.Size([32]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.conv2.weight - torch.Size([32, 32, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.bn2.weight - torch.Size([32]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.bn2.bias - torch.Size([32]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.conv3.weight - torch.Size([64, 32, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.bn3.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.bn3.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.positional_embedding - torch.Size([401, 2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.k_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.k_proj.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.q_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.q_proj.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.v_proj.weight - torch.Size([2048, 2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.v_proj.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.c_proj.weight - torch.Size([1024, 2048]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

backbone.attnpool.c_proj.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CLIPResNetWithAttention  

text_encoder.positional_embedding - torch.Size([18, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.text_projection - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.0.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.1.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.2.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.3.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.4.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.5.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.6.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.7.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.8.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.9.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.10.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.attn.in_proj_weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.attn.in_proj_bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.attn.out_proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.attn.out_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.ln_1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.ln_1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.mlp.c_fc.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.mlp.c_fc.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.mlp.c_proj.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.mlp.c_proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.ln_2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.transformer.resblocks.11.ln_2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.token_embedding.weight - torch.Size([49408, 512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.ln_final.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

text_encoder.ln_final.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CLIPTextContextEncoder  

context_decoder.memory_proj.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.memory_proj.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.memory_proj.1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.memory_proj.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.memory_proj.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.memory_proj.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.text_proj.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.text_proj.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.text_proj.1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.text_proj.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.self_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.self_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.self_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.self_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.self_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.cross_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.cross_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.cross_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.cross_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.cross_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.mlp.0.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.mlp.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.mlp.3.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.0.mlp.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.self_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.self_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.self_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.self_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.self_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.cross_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.cross_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.cross_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.cross_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.cross_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.mlp.0.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.mlp.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.mlp.3.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.1.mlp.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.self_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.self_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.self_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.self_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.self_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.cross_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.cross_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.cross_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.cross_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.cross_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.mlp.0.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.mlp.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.mlp.3.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.decoder.2.mlp.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.out_proj.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.out_proj.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.out_proj.1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

context_decoder.out_proj.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

prompt_generator.prompt_proj.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

prompt_generator.prompt_proj.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

prompt_generator.prompt_proj.1.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

prompt_generator.prompt_proj.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

prompt_generator.prompt_proj.3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

prompt_generator.prompt_proj.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

prompt_generator.prompt_proj.4.weight - torch.Size([512, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

prompt_generator.prompt_proj.4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.memory_proj.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.memory_proj.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.memory_proj.1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.memory_proj.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.memory_proj.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.memory_proj.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.text_proj.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.text_proj.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.text_proj.1.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.text_proj.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.self_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.self_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.self_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.self_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.self_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.cross_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.cross_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.cross_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.cross_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.cross_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.mlp.0.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.mlp.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.mlp.3.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.0.mlp.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.self_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.self_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.self_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.self_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.self_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.cross_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.cross_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.cross_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.cross_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.cross_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.mlp.0.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.mlp.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.mlp.3.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.1.mlp.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.self_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.self_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.self_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.self_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.self_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.cross_attn.q_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.cross_attn.k_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.cross_attn.v_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.cross_attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.cross_attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.mlp.0.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.mlp.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.mlp.3.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.decoder.2.mlp.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.out_proj.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.out_proj.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.out_proj.1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

visual_prompt_generator.out_proj.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.3.conv.weight - torch.Size([256, 2049, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.1.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.2.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.3.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

det_head.binarize.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.binarize.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.binarize.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.binarize.3.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.binarize.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.binarize.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.binarize.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.binarize.6.weight - torch.Size([64, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.binarize.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.3.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.6.weight - torch.Size([64, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of CLIPProduct  

det_head.threshold.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CLIPProduct  
2023/11/14 19:02:40 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2023/11/14 19:02:40 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2023/11/14 19:02:40 - mmengine - INFO - Checkpoints will be saved to /home/biometrics/reserve/MultimodalProduct/work_dirs/clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji.
2023/11/14 19:03:38 - mmengine - INFO - Epoch(train)    [1][ 5/16]  lr: 7.0000e-03  eta: 2 days, 13:30:39  time: 11.5363  data_time: 10.5116  memory: 19734  loss: 20.1950  loss_prob: 16.9289  loss_thr: 2.2764  loss_db: 0.9897
2023/11/14 19:03:41 - mmengine - INFO - Epoch(train)    [1][10/16]  lr: 7.0000e-03  eta: 1 day, 8:18:57  time: 6.0624  data_time: 5.2603  memory: 19734  loss: 14.2282  loss_prob: 11.4193  loss_thr: 1.8214  loss_db: 0.9876
2023/11/14 19:03:44 - mmengine - INFO - Epoch(train)    [1][15/16]  lr: 7.0000e-03  eta: 22:35:22  time: 0.5901  data_time: 0.0060  memory: 19734  loss: 6.9650  loss_prob: 4.6966  loss_thr: 1.2777  loss_db: 0.9906
2023/11/14 19:03:44 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:04:28 - mmengine - INFO - Epoch(train)    [2][ 5/16]  lr: 7.0000e-03  eta: 1 day, 3:11:27  time: 4.5980  data_time: 3.9619  memory: 19734  loss: 5.2912  loss_prob: 3.1280  loss_thr: 1.1644  loss_db: 0.9988
2023/11/14 19:04:31 - mmengine - INFO - Epoch(train)    [2][10/16]  lr: 7.0000e-03  eta: 22:33:23  time: 4.6140  data_time: 3.9630  memory: 19734  loss: 5.1309  loss_prob: 2.9773  loss_thr: 1.1537  loss_db: 1.0000
2023/11/14 19:04:33 - mmengine - INFO - Epoch(train)    [2][15/16]  lr: 7.0000e-03  eta: 19:23:58  time: 0.5761  data_time: 0.0040  memory: 19734  loss: 5.0929  loss_prob: 2.9390  loss_thr: 1.1539  loss_db: 1.0000
2023/11/14 19:04:34 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:05:17 - mmengine - INFO - Epoch(train)    [3][ 5/16]  lr: 7.0000e-03  eta: 22:27:38  time: 4.5453  data_time: 3.9772  memory: 19734  loss: 5.0469  loss_prob: 2.8911  loss_thr: 1.1558  loss_db: 1.0000
2023/11/14 19:05:20 - mmengine - INFO - Epoch(train)    [3][10/16]  lr: 7.0000e-03  eta: 20:09:25  time: 4.5757  data_time: 3.9792  memory: 19734  loss: 5.0066  loss_prob: 2.8527  loss_thr: 1.1539  loss_db: 1.0000
2023/11/14 19:05:22 - mmengine - INFO - Epoch(train)    [3][15/16]  lr: 7.0000e-03  eta: 18:19:39  time: 0.5788  data_time: 0.0047  memory: 19734  loss: 4.9870  loss_prob: 2.8333  loss_thr: 1.1537  loss_db: 1.0000
2023/11/14 19:05:23 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:06:05 - mmengine - INFO - Epoch(train)    [4][ 5/16]  lr: 7.0000e-03  eta: 20:32:36  time: 4.5074  data_time: 3.9347  memory: 19734  loss: 4.9793  loss_prob: 2.8243  loss_thr: 1.1550  loss_db: 1.0000
2023/11/14 19:06:08 - mmengine - INFO - Epoch(train)    [4][10/16]  lr: 7.0000e-03  eta: 19:01:48  time: 4.5251  data_time: 3.9351  memory: 19734  loss: 4.9734  loss_prob: 2.8197  loss_thr: 1.1538  loss_db: 1.0000
2023/11/14 19:06:11 - mmengine - INFO - Epoch(train)    [4][15/16]  lr: 7.0000e-03  eta: 17:45:18  time: 0.5708  data_time: 0.0045  memory: 19734  loss: 4.9673  loss_prob: 2.8173  loss_thr: 1.1500  loss_db: 1.0000
2023/11/14 19:06:11 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:06:54 - mmengine - INFO - Epoch(train)    [5][ 5/16]  lr: 7.0000e-03  eta: 19:29:29  time: 4.4908  data_time: 3.9255  memory: 19734  loss: 4.9696  loss_prob: 2.8163  loss_thr: 1.1533  loss_db: 1.0000
2023/11/14 19:06:56 - mmengine - INFO - Epoch(train)    [5][10/16]  lr: 7.0000e-03  eta: 18:22:36  time: 4.5129  data_time: 3.9242  memory: 19734  loss: 4.9683  loss_prob: 2.8155  loss_thr: 1.1528  loss_db: 1.0000
2023/11/14 19:06:59 - mmengine - INFO - Epoch(train)    [5][15/16]  lr: 7.0000e-03  eta: 17:24:08  time: 0.5757  data_time: 0.0031  memory: 19734  loss: 4.9646  loss_prob: 2.8151  loss_thr: 1.1496  loss_db: 0.9999
2023/11/14 19:07:00 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:07:00 - mmengine - INFO - Saving checkpoint at 5 epochs
2023/11/14 19:07:42 - mmengine - INFO - Epoch(train)    [6][ 5/16]  lr: 7.0000e-03  eta: 18:45:08  time: 4.3662  data_time: 3.7983  memory: 19734  loss: 4.9636  loss_prob: 2.8152  loss_thr: 1.1485  loss_db: 0.9999
2023/11/14 19:07:45 - mmengine - INFO - Epoch(train)    [6][10/16]  lr: 7.0000e-03  eta: 17:52:40  time: 4.3881  data_time: 3.8031  memory: 19734  loss: 4.9593  loss_prob: 2.8147  loss_thr: 1.1447  loss_db: 0.9999
2023/11/14 19:07:48 - mmengine - INFO - Epoch(train)    [6][15/16]  lr: 7.0000e-03  eta: 17:05:28  time: 0.5758  data_time: 0.0076  memory: 19734  loss: 4.9553  loss_prob: 2.8147  loss_thr: 1.1407  loss_db: 0.9999
2023/11/14 19:07:48 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:08:31 - mmengine - INFO - Epoch(train)    [7][ 5/16]  lr: 7.0000e-03  eta: 18:20:50  time: 4.5618  data_time: 3.9955  memory: 19734  loss: 4.9521  loss_prob: 2.8153  loss_thr: 1.1388  loss_db: 0.9980
2023/11/14 19:08:34 - mmengine - INFO - Epoch(train)    [7][10/16]  lr: 7.0000e-03  eta: 17:37:20  time: 4.5839  data_time: 3.9957  memory: 19734  loss: 4.9417  loss_prob: 2.8150  loss_thr: 1.1293  loss_db: 0.9973
2023/11/14 19:08:37 - mmengine - INFO - Epoch(train)    [7][15/16]  lr: 7.0000e-03  eta: 16:57:36  time: 0.5743  data_time: 0.0026  memory: 19734  loss: 4.9285  loss_prob: 2.8145  loss_thr: 1.1391  loss_db: 0.9748
2023/11/14 19:08:37 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:09:20 - mmengine - INFO - Epoch(train)    [8][ 5/16]  lr: 7.0000e-03  eta: 18:01:32  time: 4.5086  data_time: 3.9343  memory: 19734  loss: 4.9442  loss_prob: 2.8152  loss_thr: 1.1519  loss_db: 0.9771
2023/11/14 19:09:23 - mmengine - INFO - Epoch(train)    [8][10/16]  lr: 7.0000e-03  eta: 17:24:41  time: 4.5410  data_time: 3.9347  memory: 19734  loss: 4.9454  loss_prob: 2.8156  loss_thr: 1.1340  loss_db: 0.9957
2023/11/14 19:09:25 - mmengine - INFO - Epoch(train)    [8][15/16]  lr: 7.0000e-03  eta: 16:50:27  time: 0.5833  data_time: 0.0043  memory: 19734  loss: 4.9450  loss_prob: 2.8157  loss_thr: 1.1347  loss_db: 0.9946
2023/11/14 19:09:26 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:10:08 - mmengine - INFO - Epoch(train)    [9][ 5/16]  lr: 7.0000e-03  eta: 17:46:50  time: 4.5077  data_time: 3.7175  memory: 19734  loss: 4.9564  loss_prob: 2.8155  loss_thr: 1.1456  loss_db: 0.9953
2023/11/14 19:10:11 - mmengine - INFO - Epoch(train)    [9][10/16]  lr: 7.0000e-03  eta: 17:14:31  time: 4.5293  data_time: 3.7164  memory: 19734  loss: 4.9609  loss_prob: 2.8162  loss_thr: 1.1564  loss_db: 0.9883
2023/11/14 19:10:14 - mmengine - INFO - Epoch(train)    [9][15/16]  lr: 7.0000e-03  eta: 16:44:24  time: 0.5719  data_time: 0.0038  memory: 19734  loss: 4.9391  loss_prob: 2.8172  loss_thr: 1.1628  loss_db: 0.9591
2023/11/14 19:10:14 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:10:58 - mmengine - INFO - Epoch(train)   [10][ 5/16]  lr: 7.0000e-03  eta: 17:36:26  time: 4.5828  data_time: 4.0224  memory: 19734  loss: 4.9084  loss_prob: 2.8201  loss_thr: 1.1704  loss_db: 0.9179
2023/11/14 19:11:01 - mmengine - INFO - Epoch(train)   [10][10/16]  lr: 7.0000e-03  eta: 17:08:05  time: 4.6137  data_time: 4.0252  memory: 19734  loss: 4.9081  loss_prob: 2.8211  loss_thr: 1.1609  loss_db: 0.9261
2023/11/14 19:11:03 - mmengine - INFO - Epoch(train)   [10][15/16]  lr: 7.0000e-03  eta: 16:41:17  time: 0.5917  data_time: 0.0064  memory: 19734  loss: 4.8813  loss_prob: 2.8197  loss_thr: 1.1428  loss_db: 0.9188
2023/11/14 19:11:04 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:11:04 - mmengine - INFO - Saving checkpoint at 10 epochs
2023/11/14 19:11:47 - mmengine - INFO - Epoch(train)   [11][ 5/16]  lr: 7.0000e-03  eta: 17:24:32  time: 4.3918  data_time: 3.8256  memory: 19734  loss: 4.8280  loss_prob: 2.8202  loss_thr: 1.1514  loss_db: 0.8564
2023/11/14 19:11:50 - mmengine - INFO - Epoch(train)   [11][10/16]  lr: 7.0000e-03  eta: 16:59:03  time: 4.4124  data_time: 3.8281  memory: 19734  loss: 4.8335  loss_prob: 2.8204  loss_thr: 1.1705  loss_db: 0.8425
2023/11/14 19:11:52 - mmengine - INFO - Epoch(train)   [11][15/16]  lr: 7.0000e-03  eta: 16:34:54  time: 0.5837  data_time: 0.0057  memory: 19734  loss: 4.8626  loss_prob: 2.8208  loss_thr: 1.1684  loss_db: 0.8734
2023/11/14 19:11:53 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:12:35 - mmengine - INFO - Epoch(train)   [12][ 5/16]  lr: 7.0000e-03  eta: 17:15:43  time: 4.4602  data_time: 3.8110  memory: 19734  loss: 4.8793  loss_prob: 2.8211  loss_thr: 1.1546  loss_db: 0.9037
2023/11/14 19:12:38 - mmengine - INFO - Epoch(train)   [12][10/16]  lr: 7.0000e-03  eta: 16:52:35  time: 4.4844  data_time: 3.8126  memory: 19734  loss: 4.8759  loss_prob: 2.8213  loss_thr: 1.1393  loss_db: 0.9154
2023/11/14 19:12:41 - mmengine - INFO - Epoch(train)   [12][15/16]  lr: 7.0000e-03  eta: 16:30:32  time: 0.5763  data_time: 0.0047  memory: 19734  loss: 4.8376  loss_prob: 2.8221  loss_thr: 1.1541  loss_db: 0.8614
2023/11/14 19:12:41 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:13:22 - mmengine - INFO - Epoch(train)   [13][ 5/16]  lr: 7.0000e-03  eta: 17:06:37  time: 4.3678  data_time: 3.7958  memory: 19734  loss: 4.8209  loss_prob: 2.8224  loss_thr: 1.1707  loss_db: 0.8278
2023/11/14 19:13:25 - mmengine - INFO - Epoch(train)   [13][10/16]  lr: 7.0000e-03  eta: 16:45:36  time: 4.3991  data_time: 3.7970  memory: 19734  loss: 4.8347  loss_prob: 2.8233  loss_thr: 1.1438  loss_db: 0.8676
2023/11/14 19:13:28 - mmengine - INFO - Epoch(train)   [13][15/16]  lr: 7.0000e-03  eta: 16:25:24  time: 0.5817  data_time: 0.0042  memory: 19734  loss: 4.8675  loss_prob: 2.8233  loss_thr: 1.1390  loss_db: 0.9053
2023/11/14 19:13:28 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:14:09 - mmengine - INFO - Epoch(train)   [14][ 5/16]  lr: 7.0000e-03  eta: 16:58:34  time: 4.3480  data_time: 3.7096  memory: 19734  loss: 4.8769  loss_prob: 2.8227  loss_thr: 1.1542  loss_db: 0.9000
2023/11/14 19:14:12 - mmengine - INFO - Epoch(train)   [14][10/16]  lr: 7.0000e-03  eta: 16:39:12  time: 4.3749  data_time: 3.7133  memory: 19734  loss: 4.8688  loss_prob: 2.8216  loss_thr: 1.1658  loss_db: 0.8814
2023/11/14 19:14:15 - mmengine - INFO - Epoch(train)   [14][15/16]  lr: 7.0000e-03  eta: 16:20:36  time: 0.5799  data_time: 0.0070  memory: 19734  loss: 4.8095  loss_prob: 2.8211  loss_thr: 1.1505  loss_db: 0.8379
2023/11/14 19:14:15 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:14:56 - mmengine - INFO - Epoch(train)   [15][ 5/16]  lr: 7.0000e-03  eta: 16:51:42  time: 4.3640  data_time: 3.5414  memory: 19734  loss: 4.7730  loss_prob: 2.8227  loss_thr: 1.1531  loss_db: 0.7971
2023/11/14 19:14:59 - mmengine - INFO - Epoch(train)   [15][10/16]  lr: 7.0000e-03  eta: 16:33:47  time: 4.3912  data_time: 3.5452  memory: 19734  loss: 4.7711  loss_prob: 2.8230  loss_thr: 1.1367  loss_db: 0.8115
2023/11/14 19:15:02 - mmengine - INFO - Epoch(train)   [15][15/16]  lr: 7.0000e-03  eta: 16:16:42  time: 0.5927  data_time: 0.0108  memory: 19734  loss: 4.7033  loss_prob: 2.8217  loss_thr: 1.1153  loss_db: 0.7662
2023/11/14 19:15:02 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:15:02 - mmengine - INFO - Saving checkpoint at 15 epochs
2023/11/14 19:15:44 - mmengine - INFO - Epoch(train)   [16][ 5/16]  lr: 7.0000e-03  eta: 16:44:24  time: 4.2650  data_time: 3.6945  memory: 19734  loss: 4.7051  loss_prob: 2.8225  loss_thr: 1.1124  loss_db: 0.7703
2023/11/14 19:15:47 - mmengine - INFO - Epoch(train)   [16][10/16]  lr: 7.0000e-03  eta: 16:27:48  time: 4.2841  data_time: 3.6958  memory: 19734  loss: 4.7310  loss_prob: 2.8228  loss_thr: 1.1237  loss_db: 0.7846
2023/11/14 19:15:49 - mmengine - INFO - Epoch(train)   [16][15/16]  lr: 7.0000e-03  eta: 16:11:47  time: 0.5876  data_time: 0.0073  memory: 19734  loss: 4.7478  loss_prob: 2.8251  loss_thr: 1.1170  loss_db: 0.8058
2023/11/14 19:15:50 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:16:31 - mmengine - INFO - Epoch(train)   [17][ 5/16]  lr: 7.0000e-03  eta: 16:39:45  time: 4.4187  data_time: 3.6647  memory: 19734  loss: 4.6999  loss_prob: 2.8289  loss_thr: 1.1123  loss_db: 0.7586
2023/11/14 19:16:34 - mmengine - INFO - Epoch(train)   [17][10/16]  lr: 7.0000e-03  eta: 16:24:07  time: 4.4350  data_time: 3.6643  memory: 19734  loss: 4.7160  loss_prob: 2.8234  loss_thr: 1.1187  loss_db: 0.7738
2023/11/14 19:16:37 - mmengine - INFO - Epoch(train)   [17][15/16]  lr: 7.0000e-03  eta: 16:09:05  time: 0.5788  data_time: 0.0049  memory: 19734  loss: 4.7358  loss_prob: 2.8243  loss_thr: 1.1108  loss_db: 0.8008
2023/11/14 19:16:38 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:17:19 - mmengine - INFO - Epoch(train)   [18][ 5/16]  lr: 7.0000e-03  eta: 16:35:47  time: 4.4495  data_time: 3.7885  memory: 19734  loss: 4.7293  loss_prob: 2.8245  loss_thr: 1.1140  loss_db: 0.7908
2023/11/14 19:17:22 - mmengine - INFO - Epoch(train)   [18][10/16]  lr: 7.0000e-03  eta: 16:21:07  time: 4.4663  data_time: 3.7874  memory: 19734  loss: 4.7246  loss_prob: 2.8247  loss_thr: 1.1000  loss_db: 0.7999
2023/11/14 19:17:25 - mmengine - INFO - Epoch(train)   [18][15/16]  lr: 7.0000e-03  eta: 16:06:59  time: 0.5822  data_time: 0.0043  memory: 19734  loss: 4.6512  loss_prob: 2.8264  loss_thr: 1.0862  loss_db: 0.7385
2023/11/14 19:17:26 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:18:07 - mmengine - INFO - Epoch(train)   [19][ 5/16]  lr: 7.0000e-03  eta: 16:31:40  time: 4.4009  data_time: 3.6763  memory: 19734  loss: 4.6065  loss_prob: 2.8239  loss_thr: 1.0702  loss_db: 0.7125
2023/11/14 19:18:10 - mmengine - INFO - Epoch(train)   [19][10/16]  lr: 7.0000e-03  eta: 16:17:49  time: 4.4131  data_time: 3.6753  memory: 19734  loss: 4.5951  loss_prob: 2.8240  loss_thr: 1.0690  loss_db: 0.7021
2023/11/14 19:18:13 - mmengine - INFO - Epoch(train)   [19][15/16]  lr: 7.0000e-03  eta: 16:04:29  time: 0.5816  data_time: 0.0036  memory: 19734  loss: 4.6059  loss_prob: 2.8238  loss_thr: 1.0855  loss_db: 0.6965
2023/11/14 19:18:13 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:18:55 - mmengine - INFO - Epoch(train)   [20][ 5/16]  lr: 7.0000e-03  eta: 16:28:16  time: 4.4351  data_time: 3.8787  memory: 19734  loss: 4.5754  loss_prob: 2.8242  loss_thr: 1.0860  loss_db: 0.6652
2023/11/14 19:18:58 - mmengine - INFO - Epoch(train)   [20][10/16]  lr: 7.0000e-03  eta: 16:15:13  time: 4.4573  data_time: 3.8787  memory: 19734  loss: 4.6269  loss_prob: 2.8246  loss_thr: 1.0846  loss_db: 0.7177
2023/11/14 19:19:00 - mmengine - INFO - Epoch(train)   [20][15/16]  lr: 7.0000e-03  eta: 16:02:30  time: 0.5804  data_time: 0.0037  memory: 19734  loss: 4.6617  loss_prob: 2.8239  loss_thr: 1.0871  loss_db: 0.7506
2023/11/14 19:19:01 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:19:01 - mmengine - INFO - Saving checkpoint at 20 epochs
2023/11/14 19:19:04 - mmengine - INFO - Epoch(val)   [20][  5/125]    eta: 0:00:52  time: 0.4363  data_time: 0.3981  memory: 13005  
2023/11/14 19:19:05 - mmengine - INFO - Epoch(val)   [20][ 10/125]    eta: 0:00:27  time: 0.2372  data_time: 0.1999  memory: 2920  
2023/11/14 19:19:05 - mmengine - INFO - Epoch(val)   [20][ 15/125]    eta: 0:00:18  time: 0.0379  data_time: 0.0015  memory: 2920  
2023/11/14 19:19:05 - mmengine - INFO - Epoch(val)   [20][ 20/125]    eta: 0:00:14  time: 0.0375  data_time: 0.0013  memory: 2920  
2023/11/14 19:19:05 - mmengine - INFO - Epoch(val)   [20][ 25/125]    eta: 0:00:11  time: 0.0384  data_time: 0.0025  memory: 2920  
2023/11/14 19:19:05 - mmengine - INFO - Epoch(val)   [20][ 30/125]    eta: 0:00:10  time: 0.0435  data_time: 0.0075  memory: 2920  
2023/11/14 19:19:06 - mmengine - INFO - Epoch(val)   [20][ 35/125]    eta: 0:00:08  time: 0.0474  data_time: 0.0115  memory: 2920  
2023/11/14 19:19:06 - mmengine - INFO - Epoch(val)   [20][ 40/125]    eta: 0:00:07  time: 0.0423  data_time: 0.0065  memory: 2920  
2023/11/14 19:19:06 - mmengine - INFO - Epoch(val)   [20][ 45/125]    eta: 0:00:06  time: 0.0445  data_time: 0.0085  memory: 2920  
2023/11/14 19:19:06 - mmengine - INFO - Epoch(val)   [20][ 50/125]    eta: 0:00:06  time: 0.0479  data_time: 0.0119  memory: 2920  
2023/11/14 19:19:06 - mmengine - INFO - Epoch(val)   [20][ 55/125]    eta: 0:00:05  time: 0.0432  data_time: 0.0072  memory: 2920  
2023/11/14 19:19:07 - mmengine - INFO - Epoch(val)   [20][ 60/125]    eta: 0:00:04  time: 0.0438  data_time: 0.0077  memory: 2920  
2023/11/14 19:19:07 - mmengine - INFO - Epoch(val)   [20][ 65/125]    eta: 0:00:04  time: 0.0506  data_time: 0.0145  memory: 2920  
2023/11/14 19:19:07 - mmengine - INFO - Epoch(val)   [20][ 70/125]    eta: 0:00:03  time: 0.0485  data_time: 0.0124  memory: 2920  
2023/11/14 19:19:07 - mmengine - INFO - Epoch(val)   [20][ 75/125]    eta: 0:00:03  time: 0.0445  data_time: 0.0084  memory: 2920  
2023/11/14 19:19:08 - mmengine - INFO - Epoch(val)   [20][ 80/125]    eta: 0:00:03  time: 0.0425  data_time: 0.0066  memory: 2920  
2023/11/14 19:19:08 - mmengine - INFO - Epoch(val)   [20][ 85/125]    eta: 0:00:02  time: 0.0444  data_time: 0.0084  memory: 2920  
2023/11/14 19:19:08 - mmengine - INFO - Epoch(val)   [20][ 90/125]    eta: 0:00:02  time: 0.0447  data_time: 0.0086  memory: 2920  
2023/11/14 19:19:08 - mmengine - INFO - Epoch(val)   [20][ 95/125]    eta: 0:00:01  time: 0.0376  data_time: 0.0017  memory: 2920  
2023/11/14 19:19:08 - mmengine - INFO - Epoch(val)   [20][100/125]    eta: 0:00:01  time: 0.0438  data_time: 0.0079  memory: 2920  
2023/11/14 19:19:09 - mmengine - INFO - Epoch(val)   [20][105/125]    eta: 0:00:01  time: 0.0504  data_time: 0.0145  memory: 2920  
2023/11/14 19:19:09 - mmengine - INFO - Epoch(val)   [20][110/125]    eta: 0:00:00  time: 0.0499  data_time: 0.0140  memory: 2920  
2023/11/14 19:19:09 - mmengine - INFO - Epoch(val)   [20][115/125]    eta: 0:00:00  time: 0.0437  data_time: 0.0077  memory: 2920  
2023/11/14 19:19:09 - mmengine - INFO - Epoch(val)   [20][120/125]    eta: 0:00:00  time: 0.0437  data_time: 0.0077  memory: 2920  
2023/11/14 19:19:10 - mmengine - INFO - Epoch(val)   [20][125/125]    eta: 0:00:00  time: 0.0449  data_time: 0.0085  memory: 2920  
2023/11/14 19:19:10 - mmengine - INFO - Evaluating hmean-iou...
2023/11/14 19:19:10 - mmengine - INFO - prediction score threshold: 0.30, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:19:10 - mmengine - INFO - prediction score threshold: 0.40, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:19:10 - mmengine - INFO - prediction score threshold: 0.50, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:19:10 - mmengine - INFO - prediction score threshold: 0.60, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:19:10 - mmengine - INFO - prediction score threshold: 0.70, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:19:10 - mmengine - INFO - prediction score threshold: 0.80, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:19:10 - mmengine - INFO - prediction score threshold: 0.90, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:19:10 - mmengine - INFO - Epoch(val) [20][125/125]    icdar/precision: 0.0000  icdar/recall: 0.0000  icdar/hmean: 0.0000  data_time: 0.0235  time: 0.0597
2023/11/14 19:19:52 - mmengine - INFO - Epoch(train)   [21][ 5/16]  lr: 7.0000e-03  eta: 16:25:26  time: 4.4635  data_time: 3.9052  memory: 19734  loss: 4.6151  loss_prob: 2.8248  loss_thr: 1.0770  loss_db: 0.7134
2023/11/14 19:19:55 - mmengine - INFO - Epoch(train)   [21][10/16]  lr: 7.0000e-03  eta: 16:12:59  time: 4.4838  data_time: 3.9079  memory: 19734  loss: 4.6250  loss_prob: 2.8253  loss_thr: 1.0798  loss_db: 0.7199
2023/11/14 19:19:57 - mmengine - INFO - Epoch(train)   [21][15/16]  lr: 7.0000e-03  eta: 16:00:56  time: 0.5771  data_time: 0.0067  memory: 19734  loss: 4.6940  loss_prob: 2.8250  loss_thr: 1.0921  loss_db: 0.7770
2023/11/14 19:19:58 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:20:40 - mmengine - INFO - Epoch(train)   [22][ 5/16]  lr: 7.0000e-03  eta: 16:22:43  time: 4.4639  data_time: 3.8746  memory: 19734  loss: 4.6639  loss_prob: 2.8249  loss_thr: 1.0889  loss_db: 0.7502
2023/11/14 19:20:43 - mmengine - INFO - Epoch(train)   [22][10/16]  lr: 7.0000e-03  eta: 16:10:51  time: 4.4780  data_time: 3.8766  memory: 19734  loss: 4.5571  loss_prob: 2.8241  loss_thr: 1.0583  loss_db: 0.6747
2023/11/14 19:20:46 - mmengine - INFO - Epoch(train)   [22][15/16]  lr: 7.0000e-03  eta: 15:59:21  time: 0.5740  data_time: 0.0077  memory: 19734  loss: 4.5645  loss_prob: 2.8237  loss_thr: 1.0620  loss_db: 0.6788
2023/11/14 19:20:46 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:21:28 - mmengine - INFO - Epoch(train)   [23][ 5/16]  lr: 7.0000e-03  eta: 16:20:21  time: 4.4833  data_time: 3.8835  memory: 19734  loss: 4.5364  loss_prob: 2.8246  loss_thr: 1.0528  loss_db: 0.6590
2023/11/14 19:21:31 - mmengine - INFO - Epoch(train)   [23][10/16]  lr: 7.0000e-03  eta: 16:09:04  time: 4.5054  data_time: 3.8831  memory: 19734  loss: 4.5693  loss_prob: 2.8250  loss_thr: 1.0735  loss_db: 0.6708
2023/11/14 19:21:34 - mmengine - INFO - Epoch(train)   [23][15/16]  lr: 7.0000e-03  eta: 15:58:04  time: 0.5775  data_time: 0.0043  memory: 19734  loss: 4.5589  loss_prob: 2.8253  loss_thr: 1.0745  loss_db: 0.6591
2023/11/14 19:21:34 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:22:16 - mmengine - INFO - Epoch(train)   [24][ 5/16]  lr: 7.0000e-03  eta: 16:17:54  time: 4.4491  data_time: 3.8867  memory: 19734  loss: 4.5178  loss_prob: 2.8246  loss_thr: 1.0449  loss_db: 0.6482
2023/11/14 19:22:19 - mmengine - INFO - Epoch(train)   [24][10/16]  lr: 7.0000e-03  eta: 16:07:06  time: 4.4771  data_time: 3.8872  memory: 19734  loss: 4.5513  loss_prob: 2.8245  loss_thr: 1.0492  loss_db: 0.6776
2023/11/14 19:22:22 - mmengine - INFO - Epoch(train)   [24][15/16]  lr: 7.0000e-03  eta: 15:56:35  time: 0.5775  data_time: 0.0044  memory: 19734  loss: 4.5259  loss_prob: 2.8255  loss_thr: 1.0356  loss_db: 0.6648
2023/11/14 19:22:22 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:23:04 - mmengine - INFO - Epoch(train)   [25][ 5/16]  lr: 7.0000e-03  eta: 16:15:28  time: 4.4401  data_time: 3.7148  memory: 19734  loss: 4.4966  loss_prob: 2.8260  loss_thr: 1.0140  loss_db: 0.6566
2023/11/14 19:23:07 - mmengine - INFO - Epoch(train)   [25][10/16]  lr: 7.0000e-03  eta: 16:05:12  time: 4.4687  data_time: 3.7144  memory: 19734  loss: 4.5147  loss_prob: 2.8266  loss_thr: 1.0313  loss_db: 0.6568
2023/11/14 19:23:10 - mmengine - INFO - Epoch(train)   [25][15/16]  lr: 7.0000e-03  eta: 15:55:08  time: 0.5878  data_time: 0.0038  memory: 19734  loss: 4.5672  loss_prob: 2.8271  loss_thr: 1.0492  loss_db: 0.6909
2023/11/14 19:23:10 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:23:10 - mmengine - INFO - Saving checkpoint at 25 epochs
2023/11/14 19:23:52 - mmengine - INFO - Epoch(train)   [26][ 5/16]  lr: 7.0000e-03  eta: 16:12:31  time: 4.3475  data_time: 3.7821  memory: 19734  loss: 4.6273  loss_prob: 2.8282  loss_thr: 1.0602  loss_db: 0.7389
2023/11/14 19:23:55 - mmengine - INFO - Epoch(train)   [26][10/16]  lr: 7.0000e-03  eta: 16:02:38  time: 4.3699  data_time: 3.7822  memory: 19734  loss: 4.6164  loss_prob: 2.8328  loss_thr: 1.0758  loss_db: 0.7078
2023/11/14 19:23:58 - mmengine - INFO - Epoch(train)   [26][15/16]  lr: 7.0000e-03  eta: 15:52:56  time: 0.5788  data_time: 0.0037  memory: 19734  loss: 4.5900  loss_prob: 2.8321  loss_thr: 1.0700  loss_db: 0.6879
2023/11/14 19:23:58 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:24:40 - mmengine - INFO - Epoch(train)   [27][ 5/16]  lr: 7.0000e-03  eta: 16:10:33  time: 4.4669  data_time: 3.9104  memory: 19734  loss: 4.6380  loss_prob: 2.8271  loss_thr: 1.0742  loss_db: 0.7366
2023/11/14 19:24:43 - mmengine - INFO - Epoch(train)   [27][10/16]  lr: 7.0000e-03  eta: 16:01:01  time: 4.4874  data_time: 3.9126  memory: 19734  loss: 4.6176  loss_prob: 2.8262  loss_thr: 1.0483  loss_db: 0.7431
2023/11/14 19:24:46 - mmengine - INFO - Epoch(train)   [27][15/16]  lr: 7.0000e-03  eta: 15:51:44  time: 0.5790  data_time: 0.0055  memory: 19734  loss: 4.5219  loss_prob: 2.8251  loss_thr: 1.0205  loss_db: 0.6763
2023/11/14 19:24:47 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:25:28 - mmengine - INFO - Epoch(train)   [28][ 5/16]  lr: 7.0000e-03  eta: 16:08:13  time: 4.4043  data_time: 3.7297  memory: 19734  loss: 4.5315  loss_prob: 2.8245  loss_thr: 1.0253  loss_db: 0.6817
2023/11/14 19:25:31 - mmengine - INFO - Epoch(train)   [28][10/16]  lr: 7.0000e-03  eta: 15:59:05  time: 4.4240  data_time: 3.7319  memory: 19734  loss: 4.5348  loss_prob: 2.8250  loss_thr: 1.0366  loss_db: 0.6733
2023/11/14 19:25:34 - mmengine - INFO - Epoch(train)   [28][15/16]  lr: 7.0000e-03  eta: 15:50:08  time: 0.5820  data_time: 0.0061  memory: 19734  loss: 4.5357  loss_prob: 2.8257  loss_thr: 1.0453  loss_db: 0.6647
2023/11/14 19:25:34 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:26:15 - mmengine - INFO - Epoch(train)   [29][ 5/16]  lr: 7.0000e-03  eta: 16:05:49  time: 4.3735  data_time: 3.8186  memory: 19734  loss: 4.5393  loss_prob: 2.8258  loss_thr: 1.0467  loss_db: 0.6668
2023/11/14 19:26:18 - mmengine - INFO - Epoch(train)   [29][10/16]  lr: 7.0000e-03  eta: 15:57:02  time: 4.3993  data_time: 3.8204  memory: 19734  loss: 4.5177  loss_prob: 2.8261  loss_thr: 1.0459  loss_db: 0.6457
2023/11/14 19:26:21 - mmengine - INFO - Epoch(train)   [29][15/16]  lr: 7.0000e-03  eta: 15:48:24  time: 0.5853  data_time: 0.0053  memory: 19734  loss: 4.4905  loss_prob: 2.8264  loss_thr: 1.0351  loss_db: 0.6290
2023/11/14 19:26:21 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:27:04 - mmengine - INFO - Epoch(train)   [30][ 5/16]  lr: 7.0000e-03  eta: 16:04:28  time: 4.5133  data_time: 3.7238  memory: 19734  loss: 4.5105  loss_prob: 2.8272  loss_thr: 1.0423  loss_db: 0.6410
2023/11/14 19:27:07 - mmengine - INFO - Epoch(train)   [30][10/16]  lr: 7.0000e-03  eta: 15:55:54  time: 4.5231  data_time: 3.7241  memory: 19734  loss: 4.4986  loss_prob: 2.8292  loss_thr: 1.0283  loss_db: 0.6411
2023/11/14 19:27:10 - mmengine - INFO - Epoch(train)   [30][15/16]  lr: 7.0000e-03  eta: 15:47:35  time: 0.5771  data_time: 0.0036  memory: 19734  loss: 4.4677  loss_prob: 2.8290  loss_thr: 1.0314  loss_db: 0.6074
2023/11/14 19:27:10 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:27:10 - mmengine - INFO - Saving checkpoint at 30 epochs
2023/11/14 19:27:51 - mmengine - INFO - Epoch(train)   [31][ 5/16]  lr: 7.0000e-03  eta: 16:01:34  time: 4.2788  data_time: 3.7060  memory: 19734  loss: 4.4989  loss_prob: 2.8292  loss_thr: 1.0140  loss_db: 0.6557
2023/11/14 19:27:54 - mmengine - INFO - Epoch(train)   [31][10/16]  lr: 7.0000e-03  eta: 15:53:22  time: 4.2983  data_time: 3.7063  memory: 19734  loss: 4.4456  loss_prob: 2.8295  loss_thr: 1.0064  loss_db: 0.6097
2023/11/14 19:27:57 - mmengine - INFO - Epoch(train)   [31][15/16]  lr: 7.0000e-03  eta: 15:45:20  time: 0.5855  data_time: 0.0043  memory: 19734  loss: 4.4627  loss_prob: 2.8295  loss_thr: 1.0147  loss_db: 0.6185
2023/11/14 19:27:58 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:28:39 - mmengine - INFO - Epoch(train)   [32][ 5/16]  lr: 7.0000e-03  eta: 15:59:48  time: 4.4277  data_time: 3.6315  memory: 19734  loss: 4.4613  loss_prob: 2.8291  loss_thr: 1.0063  loss_db: 0.6259
2023/11/14 19:28:42 - mmengine - INFO - Epoch(train)   [32][10/16]  lr: 7.0000e-03  eta: 15:51:50  time: 4.4458  data_time: 3.6324  memory: 19734  loss: 4.4855  loss_prob: 2.8291  loss_thr: 1.0239  loss_db: 0.6325
2023/11/14 19:28:45 - mmengine - INFO - Epoch(train)   [32][15/16]  lr: 7.0000e-03  eta: 15:44:03  time: 0.5800  data_time: 0.0081  memory: 19734  loss: 4.4944  loss_prob: 2.8291  loss_thr: 1.0431  loss_db: 0.6222
2023/11/14 19:28:45 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:29:27 - mmengine - INFO - Epoch(train)   [33][ 5/16]  lr: 7.0000e-03  eta: 15:58:11  time: 4.4443  data_time: 3.8925  memory: 19734  loss: 4.4737  loss_prob: 2.8296  loss_thr: 1.0254  loss_db: 0.6187
2023/11/14 19:29:30 - mmengine - INFO - Epoch(train)   [33][10/16]  lr: 7.0000e-03  eta: 15:50:28  time: 4.4613  data_time: 3.8918  memory: 19734  loss: 4.4485  loss_prob: 2.8292  loss_thr: 1.0016  loss_db: 0.6177
2023/11/14 19:29:33 - mmengine - INFO - Epoch(train)   [33][15/16]  lr: 7.0000e-03  eta: 15:42:55  time: 0.5801  data_time: 0.0028  memory: 19734  loss: 4.4158  loss_prob: 2.8275  loss_thr: 1.0042  loss_db: 0.5842
2023/11/14 19:29:33 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:30:15 - mmengine - INFO - Epoch(train)   [34][ 5/16]  lr: 7.0000e-03  eta: 15:56:22  time: 4.4066  data_time: 3.8167  memory: 19734  loss: 4.3963  loss_prob: 2.8267  loss_thr: 0.9986  loss_db: 0.5710
2023/11/14 19:30:18 - mmengine - INFO - Epoch(train)   [34][10/16]  lr: 7.0000e-03  eta: 15:48:56  time: 4.4297  data_time: 3.8167  memory: 19734  loss: 4.4311  loss_prob: 2.8278  loss_thr: 1.0044  loss_db: 0.5989
2023/11/14 19:30:21 - mmengine - INFO - Epoch(train)   [34][15/16]  lr: 7.0000e-03  eta: 15:41:36  time: 0.5860  data_time: 0.0040  memory: 19734  loss: 4.4431  loss_prob: 2.8289  loss_thr: 1.0106  loss_db: 0.6037
2023/11/14 19:30:21 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:31:03 - mmengine - INFO - Epoch(train)   [35][ 5/16]  lr: 7.0000e-03  eta: 15:54:51  time: 4.4444  data_time: 3.8765  memory: 19734  loss: 4.4370  loss_prob: 2.8285  loss_thr: 1.0081  loss_db: 0.6004
2023/11/14 19:31:06 - mmengine - INFO - Epoch(train)   [35][10/16]  lr: 7.0000e-03  eta: 15:47:39  time: 4.4663  data_time: 3.8775  memory: 19734  loss: 4.4173  loss_prob: 2.8274  loss_thr: 0.9915  loss_db: 0.5984
2023/11/14 19:31:09 - mmengine - INFO - Epoch(train)   [35][15/16]  lr: 7.0000e-03  eta: 15:40:32  time: 0.5855  data_time: 0.0069  memory: 19734  loss: 4.4178  loss_prob: 2.8268  loss_thr: 0.9987  loss_db: 0.5923
2023/11/14 19:31:09 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:31:09 - mmengine - INFO - Saving checkpoint at 35 epochs
2023/11/14 19:31:51 - mmengine - INFO - Epoch(train)   [36][ 5/16]  lr: 7.0000e-03  eta: 15:52:48  time: 4.3351  data_time: 3.7684  memory: 19734  loss: 4.3863  loss_prob: 2.8263  loss_thr: 0.9945  loss_db: 0.5654
2023/11/14 19:31:54 - mmengine - INFO - Epoch(train)   [36][10/16]  lr: 7.0000e-03  eta: 15:45:46  time: 4.3513  data_time: 3.7675  memory: 19734  loss: 4.3693  loss_prob: 2.8262  loss_thr: 0.9720  loss_db: 0.5711
2023/11/14 19:31:57 - mmengine - INFO - Epoch(train)   [36][15/16]  lr: 7.0000e-03  eta: 15:38:51  time: 0.5798  data_time: 0.0047  memory: 19734  loss: 4.4531  loss_prob: 2.8289  loss_thr: 0.9885  loss_db: 0.6357
2023/11/14 19:31:57 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:32:39 - mmengine - INFO - Epoch(train)   [37][ 5/16]  lr: 7.0000e-03  eta: 15:51:21  time: 4.4438  data_time: 3.7678  memory: 19734  loss: 4.4906  loss_prob: 2.8306  loss_thr: 1.0133  loss_db: 0.6467
2023/11/14 19:32:42 - mmengine - INFO - Epoch(train)   [37][10/16]  lr: 7.0000e-03  eta: 15:44:31  time: 4.4604  data_time: 3.7688  memory: 19734  loss: 4.4203  loss_prob: 2.8284  loss_thr: 0.9964  loss_db: 0.5954
2023/11/14 19:32:45 - mmengine - INFO - Epoch(train)   [37][15/16]  lr: 7.0000e-03  eta: 15:37:46  time: 0.5749  data_time: 0.0056  memory: 19734  loss: 4.4830  loss_prob: 2.8264  loss_thr: 1.0165  loss_db: 0.6401
2023/11/14 19:32:45 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:33:26 - mmengine - INFO - Epoch(train)   [38][ 5/16]  lr: 7.0000e-03  eta: 15:49:42  time: 4.3984  data_time: 3.7249  memory: 19734  loss: 4.4479  loss_prob: 2.8251  loss_thr: 1.0169  loss_db: 0.6060
2023/11/14 19:33:29 - mmengine - INFO - Epoch(train)   [38][10/16]  lr: 7.0000e-03  eta: 15:43:04  time: 4.4221  data_time: 3.7265  memory: 19734  loss: 4.4106  loss_prob: 2.8255  loss_thr: 0.9892  loss_db: 0.5959
2023/11/14 19:33:32 - mmengine - INFO - Epoch(train)   [38][15/16]  lr: 7.0000e-03  eta: 15:36:32  time: 0.5855  data_time: 0.0053  memory: 19734  loss: 4.4469  loss_prob: 2.8264  loss_thr: 1.0057  loss_db: 0.6148
2023/11/14 19:33:32 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:34:13 - mmengine - INFO - Epoch(train)   [39][ 5/16]  lr: 7.0000e-03  eta: 15:47:53  time: 4.3498  data_time: 3.7718  memory: 19734  loss: 4.4403  loss_prob: 2.8267  loss_thr: 1.0050  loss_db: 0.6086
2023/11/14 19:34:16 - mmengine - INFO - Epoch(train)   [39][10/16]  lr: 7.0000e-03  eta: 15:41:24  time: 4.3682  data_time: 3.7721  memory: 19734  loss: 4.4405  loss_prob: 2.8260  loss_thr: 0.9879  loss_db: 0.6267
2023/11/14 19:34:19 - mmengine - INFO - Epoch(train)   [39][15/16]  lr: 7.0000e-03  eta: 15:35:03  time: 0.5797  data_time: 0.0057  memory: 19734  loss: 4.4894  loss_prob: 2.8248  loss_thr: 1.0163  loss_db: 0.6483
2023/11/14 19:34:19 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:35:02 - mmengine - INFO - Epoch(train)   [40][ 5/16]  lr: 7.0000e-03  eta: 15:46:59  time: 4.5322  data_time: 3.9483  memory: 19734  loss: 4.4395  loss_prob: 2.8214  loss_thr: 1.0196  loss_db: 0.5985
2023/11/14 19:35:05 - mmengine - INFO - Epoch(train)   [40][10/16]  lr: 7.0000e-03  eta: 15:40:40  time: 4.5458  data_time: 3.9467  memory: 19734  loss: 4.2836  loss_prob: 2.8180  loss_thr: 0.9642  loss_db: 0.5014
2023/11/14 19:35:08 - mmengine - INFO - Epoch(train)   [40][15/16]  lr: 7.0000e-03  eta: 15:34:28  time: 0.5800  data_time: 0.0047  memory: 19734  loss: 4.2983  loss_prob: 2.8201  loss_thr: 0.9662  loss_db: 0.5120
2023/11/14 19:35:08 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:35:08 - mmengine - INFO - Saving checkpoint at 40 epochs
2023/11/14 19:35:10 - mmengine - INFO - Epoch(val)   [40][  5/125]    eta: 0:00:08  time: 0.0552  data_time: 0.0175  memory: 13005  
2023/11/14 19:35:10 - mmengine - INFO - Epoch(val)   [40][ 10/125]    eta: 0:00:06  time: 0.0557  data_time: 0.0182  memory: 2920  
2023/11/14 19:35:10 - mmengine - INFO - Epoch(val)   [40][ 15/125]    eta: 0:00:06  time: 0.0487  data_time: 0.0103  memory: 2920  
2023/11/14 19:35:11 - mmengine - INFO - Epoch(val)   [40][ 20/125]    eta: 0:00:05  time: 0.0486  data_time: 0.0082  memory: 2920  
2023/11/14 19:35:11 - mmengine - INFO - Epoch(val)   [40][ 25/125]    eta: 0:00:05  time: 0.0430  data_time: 0.0036  memory: 2920  
2023/11/14 19:35:11 - mmengine - INFO - Epoch(val)   [40][ 30/125]    eta: 0:00:04  time: 0.0468  data_time: 0.0068  memory: 2920  
2023/11/14 19:35:11 - mmengine - INFO - Epoch(val)   [40][ 35/125]    eta: 0:00:04  time: 0.0446  data_time: 0.0049  memory: 2920  
2023/11/14 19:35:12 - mmengine - INFO - Epoch(val)   [40][ 40/125]    eta: 0:00:04  time: 0.0429  data_time: 0.0053  memory: 2920  
2023/11/14 19:35:12 - mmengine - INFO - Epoch(val)   [40][ 45/125]    eta: 0:00:03  time: 0.0458  data_time: 0.0077  memory: 2920  
2023/11/14 19:35:12 - mmengine - INFO - Epoch(val)   [40][ 50/125]    eta: 0:00:03  time: 0.0447  data_time: 0.0068  memory: 2920  
2023/11/14 19:35:12 - mmengine - INFO - Epoch(val)   [40][ 55/125]    eta: 0:00:03  time: 0.0460  data_time: 0.0090  memory: 2920  
2023/11/14 19:35:12 - mmengine - INFO - Epoch(val)   [40][ 60/125]    eta: 0:00:03  time: 0.0451  data_time: 0.0080  memory: 2920  
2023/11/14 19:35:13 - mmengine - INFO - Epoch(val)   [40][ 65/125]    eta: 0:00:02  time: 0.0483  data_time: 0.0098  memory: 2920  
2023/11/14 19:35:13 - mmengine - INFO - Epoch(val)   [40][ 70/125]    eta: 0:00:02  time: 0.0509  data_time: 0.0116  memory: 2920  
2023/11/14 19:35:13 - mmengine - INFO - Epoch(val)   [40][ 75/125]    eta: 0:00:02  time: 0.0450  data_time: 0.0073  memory: 2920  
2023/11/14 19:35:13 - mmengine - INFO - Epoch(val)   [40][ 80/125]    eta: 0:00:02  time: 0.0444  data_time: 0.0074  memory: 2920  
2023/11/14 19:35:14 - mmengine - INFO - Epoch(val)   [40][ 85/125]    eta: 0:00:01  time: 0.0472  data_time: 0.0088  memory: 2920  
2023/11/14 19:35:14 - mmengine - INFO - Epoch(val)   [40][ 90/125]    eta: 0:00:01  time: 0.0450  data_time: 0.0055  memory: 2920  
2023/11/14 19:35:14 - mmengine - INFO - Epoch(val)   [40][ 95/125]    eta: 0:00:01  time: 0.0421  data_time: 0.0017  memory: 2920  
2023/11/14 19:35:14 - mmengine - INFO - Epoch(val)   [40][100/125]    eta: 0:00:01  time: 0.0423  data_time: 0.0015  memory: 2920  
2023/11/14 19:35:14 - mmengine - INFO - Epoch(val)   [40][105/125]    eta: 0:00:00  time: 0.0403  data_time: 0.0016  memory: 2920  
2023/11/14 19:35:15 - mmengine - INFO - Epoch(val)   [40][110/125]    eta: 0:00:00  time: 0.0391  data_time: 0.0015  memory: 2920  
2023/11/14 19:35:15 - mmengine - INFO - Epoch(val)   [40][115/125]    eta: 0:00:00  time: 0.0396  data_time: 0.0015  memory: 2920  
2023/11/14 19:35:15 - mmengine - INFO - Epoch(val)   [40][120/125]    eta: 0:00:00  time: 0.0393  data_time: 0.0015  memory: 2920  
2023/11/14 19:35:15 - mmengine - INFO - Epoch(val)   [40][125/125]    eta: 0:00:00  time: 0.0395  data_time: 0.0014  memory: 2920  
2023/11/14 19:35:15 - mmengine - INFO - Evaluating hmean-iou...
2023/11/14 19:35:15 - mmengine - INFO - prediction score threshold: 0.30, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:35:15 - mmengine - INFO - prediction score threshold: 0.40, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:35:15 - mmengine - INFO - prediction score threshold: 0.50, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:35:15 - mmengine - INFO - prediction score threshold: 0.60, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:35:15 - mmengine - INFO - prediction score threshold: 0.70, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:35:15 - mmengine - INFO - prediction score threshold: 0.80, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:35:15 - mmengine - INFO - prediction score threshold: 0.90, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:35:15 - mmengine - INFO - Epoch(val) [40][125/125]    icdar/precision: 0.0000  icdar/recall: 0.0000  icdar/hmean: 0.0000  data_time: 0.0066  time: 0.0451
2023/11/14 19:35:58 - mmengine - INFO - Epoch(train)   [41][ 5/16]  lr: 7.0000e-03  eta: 15:46:01  time: 4.5167  data_time: 3.8391  memory: 19734  loss: 4.3867  loss_prob: 2.8229  loss_thr: 0.9986  loss_db: 0.5652
2023/11/14 19:36:01 - mmengine - INFO - Epoch(train)   [41][10/16]  lr: 7.0000e-03  eta: 15:39:52  time: 4.5377  data_time: 3.8399  memory: 19734  loss: 4.3893  loss_prob: 2.8232  loss_thr: 0.9913  loss_db: 0.5748
2023/11/14 19:36:04 - mmengine - INFO - Epoch(train)   [41][15/16]  lr: 7.0000e-03  eta: 15:33:49  time: 0.5827  data_time: 0.0052  memory: 19734  loss: 4.3887  loss_prob: 2.8224  loss_thr: 0.9824  loss_db: 0.5838
2023/11/14 19:36:04 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:36:45 - mmengine - INFO - Epoch(train)   [42][ 5/16]  lr: 7.0000e-03  eta: 15:44:34  time: 4.4079  data_time: 3.8464  memory: 19734  loss: 4.3723  loss_prob: 2.8217  loss_thr: 0.9860  loss_db: 0.5645
2023/11/14 19:36:48 - mmengine - INFO - Epoch(train)   [42][10/16]  lr: 7.0000e-03  eta: 15:38:34  time: 4.4314  data_time: 3.8495  memory: 19734  loss: 4.3432  loss_prob: 2.8181  loss_thr: 0.9807  loss_db: 0.5445
2023/11/14 19:36:51 - mmengine - INFO - Epoch(train)   [42][15/16]  lr: 7.0000e-03  eta: 15:32:39  time: 0.5790  data_time: 0.0070  memory: 19734  loss: 4.3250  loss_prob: 2.8137  loss_thr: 0.9864  loss_db: 0.5248
2023/11/14 19:36:52 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:37:34 - mmengine - INFO - Epoch(train)   [43][ 5/16]  lr: 7.0000e-03  eta: 15:43:28  time: 4.4802  data_time: 3.9123  memory: 19734  loss: 4.3539  loss_prob: 2.8088  loss_thr: 1.0049  loss_db: 0.5402
2023/11/14 19:37:37 - mmengine - INFO - Epoch(train)   [43][10/16]  lr: 7.0000e-03  eta: 15:37:36  time: 4.5018  data_time: 3.9123  memory: 19734  loss: 4.3205  loss_prob: 2.8060  loss_thr: 0.9729  loss_db: 0.5416
2023/11/14 19:37:39 - mmengine - INFO - Epoch(train)   [43][15/16]  lr: 7.0000e-03  eta: 15:31:50  time: 0.5792  data_time: 0.0049  memory: 19734  loss: 4.4030  loss_prob: 2.8114  loss_thr: 0.9861  loss_db: 0.6056
2023/11/14 19:37:40 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:38:21 - mmengine - INFO - Epoch(train)   [44][ 5/16]  lr: 7.0000e-03  eta: 15:42:04  time: 4.4116  data_time: 3.8135  memory: 19734  loss: 4.3691  loss_prob: 2.8003  loss_thr: 0.9833  loss_db: 0.5855
2023/11/14 19:38:24 - mmengine - INFO - Epoch(train)   [44][10/16]  lr: 7.0000e-03  eta: 15:36:20  time: 4.4292  data_time: 3.8154  memory: 19734  loss: 4.3612  loss_prob: 2.7889  loss_thr: 0.9830  loss_db: 0.5892
2023/11/14 19:38:27 - mmengine - INFO - Epoch(train)   [44][15/16]  lr: 7.0000e-03  eta: 15:30:42  time: 0.5811  data_time: 0.0076  memory: 19734  loss: 4.3618  loss_prob: 2.7836  loss_thr: 1.0002  loss_db: 0.5780
2023/11/14 19:38:27 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:39:09 - mmengine - INFO - Epoch(train)   [45][ 5/16]  lr: 7.0000e-03  eta: 15:40:42  time: 4.4114  data_time: 3.8452  memory: 19734  loss: 4.3405  loss_prob: 2.7805  loss_thr: 0.9948  loss_db: 0.5651
2023/11/14 19:39:12 - mmengine - INFO - Epoch(train)   [45][10/16]  lr: 7.0000e-03  eta: 15:35:09  time: 4.4397  data_time: 3.8465  memory: 19734  loss: 4.2860  loss_prob: 2.7719  loss_thr: 0.9669  loss_db: 0.5472
2023/11/14 19:39:15 - mmengine - INFO - Epoch(train)   [45][15/16]  lr: 7.0000e-03  eta: 15:29:38  time: 0.5883  data_time: 0.0057  memory: 19734  loss: 4.2179  loss_prob: 2.7497  loss_thr: 0.9459  loss_db: 0.5223
2023/11/14 19:39:15 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:39:15 - mmengine - INFO - Saving checkpoint at 45 epochs
2023/11/14 19:39:57 - mmengine - INFO - Epoch(train)   [46][ 5/16]  lr: 7.0000e-03  eta: 15:39:12  time: 4.3668  data_time: 3.8021  memory: 19734  loss: 4.2146  loss_prob: 2.7374  loss_thr: 0.9457  loss_db: 0.5315
2023/11/14 19:40:00 - mmengine - INFO - Epoch(train)   [46][10/16]  lr: 7.0000e-03  eta: 15:33:45  time: 4.3862  data_time: 3.8011  memory: 19734  loss: 4.2508  loss_prob: 2.7395  loss_thr: 0.9487  loss_db: 0.5626
2023/11/14 19:40:03 - mmengine - INFO - Epoch(train)   [46][15/16]  lr: 7.0000e-03  eta: 15:28:20  time: 0.5759  data_time: 0.0039  memory: 19734  loss: 4.2450  loss_prob: 2.7318  loss_thr: 0.9402  loss_db: 0.5730
2023/11/14 19:40:03 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:40:45 - mmengine - INFO - Epoch(train)   [47][ 5/16]  lr: 7.0000e-03  eta: 15:37:57  time: 4.4263  data_time: 3.8714  memory: 19734  loss: 4.2478  loss_prob: 2.7333  loss_thr: 0.9442  loss_db: 0.5703
2023/11/14 19:40:48 - mmengine - INFO - Epoch(train)   [47][10/16]  lr: 7.0000e-03  eta: 15:32:37  time: 4.4540  data_time: 3.8709  memory: 19734  loss: 4.1357  loss_prob: 2.6753  loss_thr: 0.9416  loss_db: 0.5188
2023/11/14 19:40:51 - mmengine - INFO - Epoch(train)   [47][15/16]  lr: 7.0000e-03  eta: 15:27:20  time: 0.5771  data_time: 0.0033  memory: 19734  loss: 4.1057  loss_prob: 2.6518  loss_thr: 0.9280  loss_db: 0.5259
2023/11/14 19:40:51 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:41:32 - mmengine - INFO - Epoch(train)   [48][ 5/16]  lr: 7.0000e-03  eta: 15:36:30  time: 4.3743  data_time: 3.7331  memory: 19734  loss: 4.1935  loss_prob: 2.6870  loss_thr: 0.9442  loss_db: 0.5623
2023/11/14 19:41:35 - mmengine - INFO - Epoch(train)   [48][10/16]  lr: 7.0000e-03  eta: 15:31:17  time: 4.3958  data_time: 3.7328  memory: 19734  loss: 4.1790  loss_prob: 2.6678  loss_thr: 0.9537  loss_db: 0.5575
2023/11/14 19:41:38 - mmengine - INFO - Epoch(train)   [48][15/16]  lr: 7.0000e-03  eta: 15:26:07  time: 0.5782  data_time: 0.0054  memory: 19734  loss: 4.1573  loss_prob: 2.6741  loss_thr: 0.9309  loss_db: 0.5523
2023/11/14 19:41:39 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:42:20 - mmengine - INFO - Epoch(train)   [49][ 5/16]  lr: 7.0000e-03  eta: 15:35:16  time: 4.4164  data_time: 3.8430  memory: 19734  loss: 4.1214  loss_prob: 2.6704  loss_thr: 0.9060  loss_db: 0.5450
2023/11/14 19:42:23 - mmengine - INFO - Epoch(train)   [49][10/16]  lr: 7.0000e-03  eta: 15:30:09  time: 4.4403  data_time: 3.8434  memory: 19734  loss: 4.0991  loss_prob: 2.6355  loss_thr: 0.9188  loss_db: 0.5448
2023/11/14 19:42:26 - mmengine - INFO - Epoch(train)   [49][15/16]  lr: 7.0000e-03  eta: 15:25:05  time: 0.5784  data_time: 0.0046  memory: 19734  loss: 4.1553  loss_prob: 2.6477  loss_thr: 0.9331  loss_db: 0.5745
2023/11/14 19:42:26 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:43:08 - mmengine - INFO - Epoch(train)   [50][ 5/16]  lr: 7.0000e-03  eta: 15:34:05  time: 4.4262  data_time: 3.7757  memory: 19734  loss: 4.0632  loss_prob: 2.6280  loss_thr: 0.9038  loss_db: 0.5314
2023/11/14 19:43:11 - mmengine - INFO - Epoch(train)   [50][10/16]  lr: 7.0000e-03  eta: 15:29:06  time: 4.4611  data_time: 3.7786  memory: 19734  loss: 4.0937  loss_prob: 2.6129  loss_thr: 0.9517  loss_db: 0.5291
2023/11/14 19:43:14 - mmengine - INFO - Epoch(train)   [50][15/16]  lr: 7.0000e-03  eta: 15:24:09  time: 0.5910  data_time: 0.0071  memory: 19734  loss: 4.1379  loss_prob: 2.6375  loss_thr: 0.9493  loss_db: 0.5512
2023/11/14 19:43:14 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:43:14 - mmengine - INFO - Saving checkpoint at 50 epochs
2023/11/14 19:43:57 - mmengine - INFO - Epoch(train)   [51][ 5/16]  lr: 7.0000e-03  eta: 15:32:55  time: 4.4226  data_time: 3.8537  memory: 19734  loss: 4.2266  loss_prob: 2.6757  loss_thr: 0.9464  loss_db: 0.6045
2023/11/14 19:44:00 - mmengine - INFO - Epoch(train)   [51][10/16]  lr: 7.0000e-03  eta: 15:28:01  time: 4.4416  data_time: 3.8526  memory: 19734  loss: 4.2433  loss_prob: 2.6884  loss_thr: 0.9410  loss_db: 0.6139
2023/11/14 19:44:03 - mmengine - INFO - Epoch(train)   [51][15/16]  lr: 7.0000e-03  eta: 15:23:09  time: 0.5778  data_time: 0.0038  memory: 19734  loss: 4.2092  loss_prob: 2.6685  loss_thr: 0.9432  loss_db: 0.5974
2023/11/14 19:44:03 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:44:44 - mmengine - INFO - Epoch(train)   [52][ 5/16]  lr: 7.0000e-03  eta: 15:31:38  time: 4.3919  data_time: 3.7416  memory: 19734  loss: 4.2216  loss_prob: 2.6712  loss_thr: 0.9539  loss_db: 0.5966
2023/11/14 19:44:47 - mmengine - INFO - Epoch(train)   [52][10/16]  lr: 7.0000e-03  eta: 15:26:50  time: 4.4172  data_time: 3.7434  memory: 19734  loss: 4.1224  loss_prob: 2.6192  loss_thr: 0.9549  loss_db: 0.5482
2023/11/14 19:44:50 - mmengine - INFO - Epoch(train)   [52][15/16]  lr: 7.0000e-03  eta: 15:22:04  time: 0.5844  data_time: 0.0056  memory: 19734  loss: 4.0248  loss_prob: 2.5699  loss_thr: 0.9341  loss_db: 0.5208
2023/11/14 19:44:51 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:45:32 - mmengine - INFO - Epoch(train)   [53][ 5/16]  lr: 7.0000e-03  eta: 15:30:30  time: 4.4296  data_time: 3.7425  memory: 19734  loss: 4.0597  loss_prob: 2.5868  loss_thr: 0.9442  loss_db: 0.5286
2023/11/14 19:45:35 - mmengine - INFO - Epoch(train)   [53][10/16]  lr: 7.0000e-03  eta: 15:25:47  time: 4.4461  data_time: 3.7430  memory: 19734  loss: 4.1092  loss_prob: 2.6356  loss_thr: 0.9223  loss_db: 0.5512
2023/11/14 19:45:38 - mmengine - INFO - Epoch(train)   [53][15/16]  lr: 7.0000e-03  eta: 15:21:08  time: 0.5826  data_time: 0.0042  memory: 19734  loss: 4.2816  loss_prob: 2.7055  loss_thr: 0.9426  loss_db: 0.6336
2023/11/14 19:45:38 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:46:20 - mmengine - INFO - Epoch(train)   [54][ 5/16]  lr: 7.0000e-03  eta: 15:29:33  time: 4.4794  data_time: 3.7371  memory: 19734  loss: 4.0701  loss_prob: 2.5843  loss_thr: 0.9277  loss_db: 0.5581
2023/11/14 19:46:23 - mmengine - INFO - Epoch(train)   [54][10/16]  lr: 7.0000e-03  eta: 15:24:55  time: 4.4922  data_time: 3.7370  memory: 19734  loss: 3.9226  loss_prob: 2.5132  loss_thr: 0.9101  loss_db: 0.4992
2023/11/14 19:46:26 - mmengine - INFO - Epoch(train)   [54][15/16]  lr: 7.0000e-03  eta: 15:20:19  time: 0.5730  data_time: 0.0037  memory: 19734  loss: 3.9598  loss_prob: 2.5259  loss_thr: 0.9247  loss_db: 0.5092
2023/11/14 19:46:27 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:47:08 - mmengine - INFO - Epoch(train)   [55][ 5/16]  lr: 7.0000e-03  eta: 15:28:33  time: 4.4627  data_time: 3.9023  memory: 19734  loss: 3.8516  loss_prob: 2.4703  loss_thr: 0.8936  loss_db: 0.4878
2023/11/14 19:47:11 - mmengine - INFO - Epoch(train)   [55][10/16]  lr: 7.0000e-03  eta: 15:24:00  time: 4.4854  data_time: 3.9039  memory: 19734  loss: 3.8511  loss_prob: 2.4764  loss_thr: 0.8979  loss_db: 0.4768
2023/11/14 19:47:14 - mmengine - INFO - Epoch(train)   [55][15/16]  lr: 7.0000e-03  eta: 15:19:31  time: 0.5840  data_time: 0.0050  memory: 19734  loss: 3.9893  loss_prob: 2.5554  loss_thr: 0.9212  loss_db: 0.5127
2023/11/14 19:47:15 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:47:15 - mmengine - INFO - Saving checkpoint at 55 epochs
2023/11/14 19:47:57 - mmengine - INFO - Epoch(train)   [56][ 5/16]  lr: 7.0000e-03  eta: 15:27:10  time: 4.3484  data_time: 3.7696  memory: 19734  loss: 3.9970  loss_prob: 2.5543  loss_thr: 0.9226  loss_db: 0.5201
2023/11/14 19:48:00 - mmengine - INFO - Epoch(train)   [56][10/16]  lr: 7.0000e-03  eta: 15:22:43  time: 4.3656  data_time: 3.7707  memory: 19734  loss: 4.0615  loss_prob: 2.5683  loss_thr: 0.9403  loss_db: 0.5528
2023/11/14 19:48:03 - mmengine - INFO - Epoch(train)   [56][15/16]  lr: 7.0000e-03  eta: 15:18:17  time: 0.5794  data_time: 0.0054  memory: 19734  loss: 4.1457  loss_prob: 2.6215  loss_thr: 0.9463  loss_db: 0.5779
2023/11/14 19:48:03 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:48:44 - mmengine - INFO - Epoch(train)   [57][ 5/16]  lr: 7.0000e-03  eta: 15:26:00  time: 4.4027  data_time: 3.8363  memory: 19734  loss: 4.0679  loss_prob: 2.6063  loss_thr: 0.9178  loss_db: 0.5439
2023/11/14 19:48:47 - mmengine - INFO - Epoch(train)   [57][10/16]  lr: 7.0000e-03  eta: 15:21:38  time: 4.4340  data_time: 3.8380  memory: 19734  loss: 4.0334  loss_prob: 2.5735  loss_thr: 0.9203  loss_db: 0.5396
2023/11/14 19:48:50 - mmengine - INFO - Epoch(train)   [57][15/16]  lr: 7.0000e-03  eta: 15:17:17  time: 0.5847  data_time: 0.0052  memory: 19734  loss: 4.0825  loss_prob: 2.5965  loss_thr: 0.9288  loss_db: 0.5572
2023/11/14 19:48:51 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:49:32 - mmengine - INFO - Epoch(train)   [58][ 5/16]  lr: 7.0000e-03  eta: 15:25:02  time: 4.4545  data_time: 3.6972  memory: 19734  loss: 4.1004  loss_prob: 2.6329  loss_thr: 0.9185  loss_db: 0.5491
2023/11/14 19:49:35 - mmengine - INFO - Epoch(train)   [58][10/16]  lr: 7.0000e-03  eta: 15:20:44  time: 4.4804  data_time: 3.6972  memory: 19734  loss: 3.8331  loss_prob: 2.4696  loss_thr: 0.8904  loss_db: 0.4731
2023/11/14 19:49:38 - mmengine - INFO - Epoch(train)   [58][15/16]  lr: 7.0000e-03  eta: 15:16:28  time: 0.5842  data_time: 0.0031  memory: 19734  loss: 3.8357  loss_prob: 2.4637  loss_thr: 0.8929  loss_db: 0.4791
2023/11/14 19:49:39 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:50:20 - mmengine - INFO - Epoch(train)   [59][ 5/16]  lr: 7.0000e-03  eta: 15:23:59  time: 4.4297  data_time: 3.8667  memory: 19734  loss: 3.9996  loss_prob: 2.5731  loss_thr: 0.9033  loss_db: 0.5232
2023/11/14 19:50:23 - mmengine - INFO - Epoch(train)   [59][10/16]  lr: 7.0000e-03  eta: 15:19:44  time: 4.4467  data_time: 3.8661  memory: 19734  loss: 4.1195  loss_prob: 2.6379  loss_thr: 0.9109  loss_db: 0.5707
2023/11/14 19:50:26 - mmengine - INFO - Epoch(train)   [59][15/16]  lr: 7.0000e-03  eta: 15:15:33  time: 0.5797  data_time: 0.0031  memory: 19734  loss: 4.0160  loss_prob: 2.5498  loss_thr: 0.9157  loss_db: 0.5505
2023/11/14 19:50:26 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:51:08 - mmengine - INFO - Epoch(train)   [60][ 5/16]  lr: 7.0000e-03  eta: 15:22:59  time: 4.4542  data_time: 3.8731  memory: 19734  loss: 3.7445  loss_prob: 2.4080  loss_thr: 0.8728  loss_db: 0.4637
2023/11/14 19:51:11 - mmengine - INFO - Epoch(train)   [60][10/16]  lr: 7.0000e-03  eta: 15:18:48  time: 4.4676  data_time: 3.8731  memory: 19734  loss: 3.8151  loss_prob: 2.4491  loss_thr: 0.8877  loss_db: 0.4784
2023/11/14 19:51:14 - mmengine - INFO - Epoch(train)   [60][15/16]  lr: 7.0000e-03  eta: 15:14:41  time: 0.5757  data_time: 0.0033  memory: 19734  loss: 3.7918  loss_prob: 2.4575  loss_thr: 0.8683  loss_db: 0.4660
2023/11/14 19:51:14 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:51:14 - mmengine - INFO - Saving checkpoint at 60 epochs
2023/11/14 19:51:16 - mmengine - INFO - Epoch(val)   [60][  5/125]    eta: 0:00:08  time: 0.0562  data_time: 0.0159  memory: 13005  
2023/11/14 19:51:16 - mmengine - INFO - Epoch(val)   [60][ 10/125]    eta: 0:00:06  time: 0.0586  data_time: 0.0170  memory: 2920  
2023/11/14 19:51:17 - mmengine - INFO - Epoch(val)   [60][ 15/125]    eta: 0:00:06  time: 0.0473  data_time: 0.0039  memory: 2920  
2023/11/14 19:51:17 - mmengine - INFO - Epoch(val)   [60][ 20/125]    eta: 0:00:05  time: 0.0465  data_time: 0.0029  memory: 2920  
2023/11/14 19:51:17 - mmengine - INFO - Epoch(val)   [60][ 25/125]    eta: 0:00:05  time: 0.0429  data_time: 0.0014  memory: 2920  
2023/11/14 19:51:17 - mmengine - INFO - Epoch(val)   [60][ 30/125]    eta: 0:00:04  time: 0.0422  data_time: 0.0016  memory: 2920  
2023/11/14 19:51:18 - mmengine - INFO - Epoch(val)   [60][ 35/125]    eta: 0:00:04  time: 0.0484  data_time: 0.0087  memory: 2920  
2023/11/14 19:51:18 - mmengine - INFO - Epoch(val)   [60][ 40/125]    eta: 0:00:04  time: 0.0495  data_time: 0.0108  memory: 2920  
2023/11/14 19:51:18 - mmengine - INFO - Epoch(val)   [60][ 45/125]    eta: 0:00:04  time: 0.0584  data_time: 0.0175  memory: 2920  
2023/11/14 19:51:18 - mmengine - INFO - Epoch(val)   [60][ 50/125]    eta: 0:00:03  time: 0.0579  data_time: 0.0164  memory: 2920  
2023/11/14 19:51:23 - mmengine - INFO - Epoch(val)   [60][ 55/125]    eta: 0:00:08  time: 0.4720  data_time: 0.0039  memory: 2920  
2023/11/14 19:51:23 - mmengine - INFO - Epoch(val)   [60][ 60/125]    eta: 0:00:07  time: 0.4723  data_time: 0.0026  memory: 2920  
2023/11/14 19:51:23 - mmengine - INFO - Epoch(val)   [60][ 65/125]    eta: 0:00:06  time: 0.0480  data_time: 0.0033  memory: 2920  
2023/11/14 19:51:24 - mmengine - INFO - Epoch(val)   [60][ 70/125]    eta: 0:00:06  time: 0.0493  data_time: 0.0040  memory: 2920  
2023/11/14 19:51:24 - mmengine - INFO - Epoch(val)   [60][ 75/125]    eta: 0:00:05  time: 0.0475  data_time: 0.0028  memory: 2920  
2023/11/14 19:51:24 - mmengine - INFO - Epoch(val)   [60][ 80/125]    eta: 0:00:04  time: 0.0467  data_time: 0.0023  memory: 2920  
2023/11/14 19:51:24 - mmengine - INFO - Epoch(val)   [60][ 85/125]    eta: 0:00:03  time: 0.0476  data_time: 0.0033  memory: 2920  
2023/11/14 19:51:25 - mmengine - INFO - Epoch(val)   [60][ 90/125]    eta: 0:00:03  time: 0.0521  data_time: 0.0046  memory: 2920  
2023/11/14 19:51:25 - mmengine - INFO - Epoch(val)   [60][ 95/125]    eta: 0:00:02  time: 0.0506  data_time: 0.0030  memory: 2920  
2023/11/14 19:51:25 - mmengine - INFO - Epoch(val)   [60][100/125]    eta: 0:00:02  time: 0.0463  data_time: 0.0017  memory: 2920  
2023/11/14 19:51:25 - mmengine - INFO - Epoch(val)   [60][105/125]    eta: 0:00:01  time: 0.0443  data_time: 0.0017  memory: 2920  
2023/11/14 19:51:25 - mmengine - INFO - Epoch(val)   [60][110/125]    eta: 0:00:01  time: 0.0460  data_time: 0.0018  memory: 2920  
2023/11/14 19:51:26 - mmengine - INFO - Epoch(val)   [60][115/125]    eta: 0:00:00  time: 0.0456  data_time: 0.0018  memory: 2920  
2023/11/14 19:51:26 - mmengine - INFO - Epoch(val)   [60][120/125]    eta: 0:00:00  time: 0.0423  data_time: 0.0017  memory: 2920  
2023/11/14 19:51:26 - mmengine - INFO - Epoch(val)   [60][125/125]    eta: 0:00:00  time: 0.0455  data_time: 0.0015  memory: 2920  
2023/11/14 19:51:26 - mmengine - INFO - Evaluating hmean-iou...
2023/11/14 19:51:26 - mmengine - INFO - prediction score threshold: 0.30, recall: 0.1950, precision: 0.1353, hmean: 0.1597

2023/11/14 19:51:26 - mmengine - INFO - prediction score threshold: 0.40, recall: 0.1907, precision: 0.2949, hmean: 0.2316

2023/11/14 19:51:26 - mmengine - INFO - prediction score threshold: 0.50, recall: 0.0631, precision: 0.6238, hmean: 0.1146

2023/11/14 19:51:26 - mmengine - INFO - prediction score threshold: 0.60, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:51:26 - mmengine - INFO - prediction score threshold: 0.70, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:51:26 - mmengine - INFO - prediction score threshold: 0.80, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:51:26 - mmengine - INFO - prediction score threshold: 0.90, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 19:51:26 - mmengine - INFO - Epoch(val) [60][125/125]    icdar/precision: 0.2949  icdar/recall: 0.1907  icdar/hmean: 0.2316  data_time: 0.0054  time: 0.0824
2023/11/14 19:52:09 - mmengine - INFO - Epoch(train)   [61][ 5/16]  lr: 7.0000e-03  eta: 15:22:23  time: 4.5770  data_time: 3.9943  memory: 19734  loss: 3.8153  loss_prob: 2.4574  loss_thr: 0.8846  loss_db: 0.4732
2023/11/14 19:52:12 - mmengine - INFO - Epoch(train)   [61][10/16]  lr: 7.0000e-03  eta: 15:18:18  time: 4.6021  data_time: 3.9972  memory: 19734  loss: 3.9628  loss_prob: 2.5312  loss_thr: 0.9101  loss_db: 0.5215
2023/11/14 19:52:15 - mmengine - INFO - Epoch(train)   [61][15/16]  lr: 7.0000e-03  eta: 15:14:15  time: 0.5858  data_time: 0.0066  memory: 19734  loss: 3.9174  loss_prob: 2.4969  loss_thr: 0.9106  loss_db: 0.5100
2023/11/14 19:52:16 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:52:58 - mmengine - INFO - Epoch(train)   [62][ 5/16]  lr: 7.0000e-03  eta: 15:21:41  time: 4.5404  data_time: 3.7889  memory: 19734  loss: 3.7503  loss_prob: 2.4062  loss_thr: 0.8823  loss_db: 0.4619
2023/11/14 19:53:01 - mmengine - INFO - Epoch(train)   [62][10/16]  lr: 7.0000e-03  eta: 15:17:39  time: 4.5569  data_time: 3.7890  memory: 19734  loss: 3.7417  loss_prob: 2.4036  loss_thr: 0.8806  loss_db: 0.4575
2023/11/14 19:53:04 - mmengine - INFO - Epoch(train)   [62][15/16]  lr: 7.0000e-03  eta: 15:13:39  time: 0.5764  data_time: 0.0043  memory: 19734  loss: 3.7165  loss_prob: 2.3691  loss_thr: 0.8953  loss_db: 0.4520
2023/11/14 19:53:04 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:53:47 - mmengine - INFO - Epoch(train)   [63][ 5/16]  lr: 7.0000e-03  eta: 15:20:54  time: 4.5157  data_time: 3.9448  memory: 19734  loss: 3.7470  loss_prob: 2.3837  loss_thr: 0.9056  loss_db: 0.4578
2023/11/14 19:53:49 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:53:50 - mmengine - INFO - Epoch(train)   [63][10/16]  lr: 7.0000e-03  eta: 15:16:55  time: 4.5352  data_time: 3.9449  memory: 19734  loss: 3.6661  loss_prob: 2.3591  loss_thr: 0.8720  loss_db: 0.4349
2023/11/14 19:53:53 - mmengine - INFO - Epoch(train)   [63][15/16]  lr: 7.0000e-03  eta: 15:13:00  time: 0.5813  data_time: 0.0045  memory: 19734  loss: 3.7712  loss_prob: 2.4173  loss_thr: 0.8895  loss_db: 0.4644
2023/11/14 19:53:53 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:54:35 - mmengine - INFO - Epoch(train)   [64][ 5/16]  lr: 7.0000e-03  eta: 15:19:53  time: 4.4409  data_time: 3.5880  memory: 19734  loss: 3.9556  loss_prob: 2.5128  loss_thr: 0.9158  loss_db: 0.5270
2023/11/14 19:54:38 - mmengine - INFO - Epoch(train)   [64][10/16]  lr: 7.0000e-03  eta: 15:15:59  time: 4.4614  data_time: 3.5902  memory: 19734  loss: 4.0979  loss_prob: 2.5833  loss_thr: 0.9342  loss_db: 0.5804
2023/11/14 19:54:41 - mmengine - INFO - Epoch(train)   [64][15/16]  lr: 7.0000e-03  eta: 15:12:08  time: 0.5862  data_time: 0.0061  memory: 19734  loss: 3.8823  loss_prob: 2.4809  loss_thr: 0.8902  loss_db: 0.5112
2023/11/14 19:54:41 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:55:22 - mmengine - INFO - Epoch(train)   [65][ 5/16]  lr: 7.0000e-03  eta: 15:18:49  time: 4.4181  data_time: 3.7928  memory: 19734  loss: 3.7099  loss_prob: 2.3910  loss_thr: 0.8659  loss_db: 0.4531
2023/11/14 19:55:25 - mmengine - INFO - Epoch(train)   [65][10/16]  lr: 7.0000e-03  eta: 15:14:58  time: 4.4303  data_time: 3.7934  memory: 19734  loss: 3.7940  loss_prob: 2.4401  loss_thr: 0.8789  loss_db: 0.4751
2023/11/14 19:55:28 - mmengine - INFO - Epoch(train)   [65][15/16]  lr: 7.0000e-03  eta: 15:11:09  time: 0.5770  data_time: 0.0038  memory: 19734  loss: 3.9214  loss_prob: 2.5092  loss_thr: 0.8957  loss_db: 0.5164
2023/11/14 19:55:29 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:55:29 - mmengine - INFO - Saving checkpoint at 65 epochs
2023/11/14 19:56:10 - mmengine - INFO - Epoch(train)   [66][ 5/16]  lr: 7.0000e-03  eta: 15:17:29  time: 4.3245  data_time: 3.7552  memory: 19734  loss: 3.9739  loss_prob: 2.5433  loss_thr: 0.9056  loss_db: 0.5250
2023/11/14 19:56:13 - mmengine - INFO - Epoch(train)   [66][10/16]  lr: 7.0000e-03  eta: 15:13:43  time: 4.3556  data_time: 3.7574  memory: 19734  loss: 3.8503  loss_prob: 2.4779  loss_thr: 0.8843  loss_db: 0.4881
2023/11/14 19:56:16 - mmengine - INFO - Epoch(train)   [66][15/16]  lr: 7.0000e-03  eta: 15:09:58  time: 0.5858  data_time: 0.0071  memory: 19734  loss: 3.7566  loss_prob: 2.4350  loss_thr: 0.8581  loss_db: 0.4635
2023/11/14 19:56:17 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:56:58 - mmengine - INFO - Epoch(train)   [67][ 5/16]  lr: 7.0000e-03  eta: 15:16:22  time: 4.3853  data_time: 3.6419  memory: 19734  loss: 3.7898  loss_prob: 2.4219  loss_thr: 0.8922  loss_db: 0.4758
2023/11/14 19:57:01 - mmengine - INFO - Epoch(train)   [67][10/16]  lr: 7.0000e-03  eta: 15:12:40  time: 4.4211  data_time: 3.6482  memory: 19734  loss: 3.8748  loss_prob: 2.4612  loss_thr: 0.9101  loss_db: 0.5035
2023/11/14 19:57:04 - mmengine - INFO - Epoch(train)   [67][15/16]  lr: 7.0000e-03  eta: 15:08:59  time: 0.5962  data_time: 0.0117  memory: 19734  loss: 3.7478  loss_prob: 2.3875  loss_thr: 0.8951  loss_db: 0.4652
2023/11/14 19:57:04 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:57:46 - mmengine - INFO - Epoch(train)   [68][ 5/16]  lr: 7.0000e-03  eta: 15:15:22  time: 4.4207  data_time: 3.7897  memory: 19734  loss: 3.8601  loss_prob: 2.4371  loss_thr: 0.9279  loss_db: 0.4951
2023/11/14 19:57:49 - mmengine - INFO - Epoch(train)   [68][10/16]  lr: 7.0000e-03  eta: 15:11:42  time: 4.4415  data_time: 3.7917  memory: 19734  loss: 4.0232  loss_prob: 2.5340  loss_thr: 0.9413  loss_db: 0.5479
2023/11/14 19:57:51 - mmengine - INFO - Epoch(train)   [68][15/16]  lr: 7.0000e-03  eta: 15:08:03  time: 0.5768  data_time: 0.0067  memory: 19734  loss: 3.9259  loss_prob: 2.5069  loss_thr: 0.8940  loss_db: 0.5250
2023/11/14 19:57:52 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:58:33 - mmengine - INFO - Epoch(train)   [69][ 5/16]  lr: 7.0000e-03  eta: 15:14:20  time: 4.4173  data_time: 3.6751  memory: 19734  loss: 3.7694  loss_prob: 2.4110  loss_thr: 0.8753  loss_db: 0.4832
2023/11/14 19:58:36 - mmengine - INFO - Epoch(train)   [69][10/16]  lr: 7.0000e-03  eta: 15:10:42  time: 4.4356  data_time: 3.6745  memory: 19734  loss: 3.6267  loss_prob: 2.3430  loss_thr: 0.8425  loss_db: 0.4411
2023/11/14 19:58:39 - mmengine - INFO - Epoch(train)   [69][15/16]  lr: 7.0000e-03  eta: 15:07:07  time: 0.5781  data_time: 0.0054  memory: 19734  loss: 3.6191  loss_prob: 2.3223  loss_thr: 0.8682  loss_db: 0.4286
2023/11/14 19:58:40 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:59:21 - mmengine - INFO - Epoch(train)   [70][ 5/16]  lr: 7.0000e-03  eta: 15:13:17  time: 4.4099  data_time: 3.6463  memory: 19734  loss: 3.8523  loss_prob: 2.4630  loss_thr: 0.8925  loss_db: 0.4968
2023/11/14 19:59:24 - mmengine - INFO - Epoch(train)   [70][10/16]  lr: 7.0000e-03  eta: 15:09:43  time: 4.4287  data_time: 3.6491  memory: 19734  loss: 3.8269  loss_prob: 2.4551  loss_thr: 0.8873  loss_db: 0.4845
2023/11/14 19:59:27 - mmengine - INFO - Epoch(train)   [70][15/16]  lr: 7.0000e-03  eta: 15:06:11  time: 0.5819  data_time: 0.0078  memory: 19734  loss: 3.7021  loss_prob: 2.3553  loss_thr: 0.8960  loss_db: 0.4507
2023/11/14 19:59:27 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 19:59:27 - mmengine - INFO - Saving checkpoint at 70 epochs
2023/11/14 20:00:09 - mmengine - INFO - Epoch(train)   [71][ 5/16]  lr: 7.0000e-03  eta: 15:11:59  time: 4.3203  data_time: 3.7507  memory: 19734  loss: 3.8651  loss_prob: 2.4532  loss_thr: 0.9135  loss_db: 0.4984
2023/11/14 20:00:12 - mmengine - INFO - Epoch(train)   [71][10/16]  lr: 7.0000e-03  eta: 15:08:29  time: 4.3366  data_time: 3.7513  memory: 19734  loss: 3.8259  loss_prob: 2.4374  loss_thr: 0.8921  loss_db: 0.4964
2023/11/14 20:00:15 - mmengine - INFO - Epoch(train)   [71][15/16]  lr: 7.0000e-03  eta: 15:05:00  time: 0.5842  data_time: 0.0050  memory: 19734  loss: 3.9515  loss_prob: 2.5273  loss_thr: 0.8937  loss_db: 0.5305
2023/11/14 20:00:15 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:00:57 - mmengine - INFO - Epoch(train)   [72][ 5/16]  lr: 7.0000e-03  eta: 15:11:04  time: 4.4452  data_time: 3.6763  memory: 19734  loss: 3.8475  loss_prob: 2.4684  loss_thr: 0.8863  loss_db: 0.4928
2023/11/14 20:01:00 - mmengine - INFO - Epoch(train)   [72][10/16]  lr: 7.0000e-03  eta: 15:07:36  time: 4.4714  data_time: 3.6780  memory: 19734  loss: 3.7334  loss_prob: 2.3872  loss_thr: 0.8826  loss_db: 0.4636
2023/11/14 20:01:03 - mmengine - INFO - Epoch(train)   [72][15/16]  lr: 7.0000e-03  eta: 15:04:10  time: 0.5785  data_time: 0.0052  memory: 19734  loss: 3.8160  loss_prob: 2.4409  loss_thr: 0.8993  loss_db: 0.4758
2023/11/14 20:01:03 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:01:45 - mmengine - INFO - Epoch(train)   [73][ 5/16]  lr: 7.0000e-03  eta: 15:10:11  time: 4.4675  data_time: 3.7092  memory: 19734  loss: 3.9172  loss_prob: 2.4916  loss_thr: 0.9041  loss_db: 0.5214
2023/11/14 20:01:48 - mmengine - INFO - Epoch(train)   [73][10/16]  lr: 7.0000e-03  eta: 15:06:45  time: 4.4814  data_time: 3.7094  memory: 19734  loss: 3.7951  loss_prob: 2.4113  loss_thr: 0.8887  loss_db: 0.4951
2023/11/14 20:01:51 - mmengine - INFO - Epoch(train)   [73][15/16]  lr: 7.0000e-03  eta: 15:03:23  time: 0.5798  data_time: 0.0048  memory: 19734  loss: 3.7161  loss_prob: 2.3665  loss_thr: 0.8941  loss_db: 0.4555
2023/11/14 20:01:51 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:02:32 - mmengine - INFO - Epoch(train)   [74][ 5/16]  lr: 7.0000e-03  eta: 15:09:03  time: 4.3689  data_time: 3.7429  memory: 19734  loss: 3.8226  loss_prob: 2.4475  loss_thr: 0.8896  loss_db: 0.4855
2023/11/14 20:02:35 - mmengine - INFO - Epoch(train)   [74][10/16]  lr: 7.0000e-03  eta: 15:05:42  time: 4.3922  data_time: 3.7454  memory: 19734  loss: 3.7022  loss_prob: 2.3574  loss_thr: 0.8854  loss_db: 0.4594
2023/11/14 20:02:38 - mmengine - INFO - Epoch(train)   [74][15/16]  lr: 7.0000e-03  eta: 15:02:22  time: 0.5914  data_time: 0.0075  memory: 19734  loss: 3.7763  loss_prob: 2.3836  loss_thr: 0.9104  loss_db: 0.4823
2023/11/14 20:02:39 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:03:19 - mmengine - INFO - Epoch(train)   [75][ 5/16]  lr: 7.0000e-03  eta: 15:07:50  time: 4.3206  data_time: 3.6979  memory: 19734  loss: 3.9282  loss_prob: 2.4948  loss_thr: 0.9169  loss_db: 0.5165
2023/11/14 20:03:22 - mmengine - INFO - Epoch(train)   [75][10/16]  lr: 7.0000e-03  eta: 15:04:31  time: 4.3438  data_time: 3.6971  memory: 19734  loss: 3.6309  loss_prob: 2.3263  loss_thr: 0.8643  loss_db: 0.4403
2023/11/14 20:03:25 - mmengine - INFO - Epoch(train)   [75][15/16]  lr: 7.0000e-03  eta: 15:01:13  time: 0.5834  data_time: 0.0034  memory: 19734  loss: 3.6204  loss_prob: 2.3271  loss_thr: 0.8563  loss_db: 0.4370
2023/11/14 20:03:25 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:03:25 - mmengine - INFO - Saving checkpoint at 75 epochs
2023/11/14 20:04:07 - mmengine - INFO - Epoch(train)   [76][ 5/16]  lr: 7.0000e-03  eta: 15:06:36  time: 4.3136  data_time: 3.7247  memory: 19734  loss: 3.7784  loss_prob: 2.4138  loss_thr: 0.8841  loss_db: 0.4804
2023/11/14 20:04:10 - mmengine - INFO - Epoch(train)   [76][10/16]  lr: 7.0000e-03  eta: 15:03:19  time: 4.3328  data_time: 3.7257  memory: 19734  loss: 3.8084  loss_prob: 2.4537  loss_thr: 0.8725  loss_db: 0.4823
2023/11/14 20:04:13 - mmengine - INFO - Epoch(train)   [76][15/16]  lr: 7.0000e-03  eta: 15:00:04  time: 0.5796  data_time: 0.0046  memory: 19734  loss: 3.8058  loss_prob: 2.4379  loss_thr: 0.8763  loss_db: 0.4916
2023/11/14 20:04:13 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:04:55 - mmengine - INFO - Epoch(train)   [77][ 5/16]  lr: 7.0000e-03  eta: 15:05:38  time: 4.4210  data_time: 3.7077  memory: 19734  loss: 3.7965  loss_prob: 2.4246  loss_thr: 0.8964  loss_db: 0.4754
2023/11/14 20:04:58 - mmengine - INFO - Epoch(train)   [77][10/16]  lr: 7.0000e-03  eta: 15:02:23  time: 4.4378  data_time: 3.7074  memory: 19734  loss: 3.8085  loss_prob: 2.4521  loss_thr: 0.8863  loss_db: 0.4702
2023/11/14 20:05:01 - mmengine - INFO - Epoch(train)   [77][15/16]  lr: 7.0000e-03  eta: 14:59:10  time: 0.5733  data_time: 0.0027  memory: 19734  loss: 3.8551  loss_prob: 2.4816  loss_thr: 0.8857  loss_db: 0.4878
2023/11/14 20:05:01 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:05:43 - mmengine - INFO - Epoch(train)   [78][ 5/16]  lr: 7.0000e-03  eta: 15:04:45  time: 4.4599  data_time: 3.7166  memory: 19734  loss: 4.0115  loss_prob: 2.5914  loss_thr: 0.8864  loss_db: 0.5337
2023/11/14 20:05:46 - mmengine - INFO - Epoch(train)   [78][10/16]  lr: 7.0000e-03  eta: 15:01:33  time: 4.4789  data_time: 3.7171  memory: 19734  loss: 3.8961  loss_prob: 2.5336  loss_thr: 0.8663  loss_db: 0.4962
2023/11/14 20:05:49 - mmengine - INFO - Epoch(train)   [78][15/16]  lr: 7.0000e-03  eta: 14:58:23  time: 0.5786  data_time: 0.0041  memory: 19734  loss: 3.5430  loss_prob: 2.2744  loss_thr: 0.8543  loss_db: 0.4143
2023/11/14 20:05:49 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:06:30 - mmengine - INFO - Epoch(train)   [79][ 5/16]  lr: 7.0000e-03  eta: 15:03:44  time: 4.4014  data_time: 3.6793  memory: 19734  loss: 3.5735  loss_prob: 2.2770  loss_thr: 0.8659  loss_db: 0.4306
2023/11/14 20:06:33 - mmengine - INFO - Epoch(train)   [79][10/16]  lr: 7.0000e-03  eta: 15:00:34  time: 4.4188  data_time: 3.6791  memory: 19734  loss: 3.7241  loss_prob: 2.3749  loss_thr: 0.8688  loss_db: 0.4805
2023/11/14 20:06:36 - mmengine - INFO - Epoch(train)   [79][15/16]  lr: 7.0000e-03  eta: 14:57:28  time: 0.5862  data_time: 0.0044  memory: 19734  loss: 3.7948  loss_prob: 2.4207  loss_thr: 0.8885  loss_db: 0.4856
2023/11/14 20:06:37 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:07:17 - mmengine - INFO - Epoch(train)   [80][ 5/16]  lr: 7.0000e-03  eta: 15:02:39  time: 4.3690  data_time: 3.7231  memory: 19734  loss: 3.7167  loss_prob: 2.3753  loss_thr: 0.8808  loss_db: 0.4606
2023/11/14 20:07:20 - mmengine - INFO - Epoch(train)   [80][10/16]  lr: 7.0000e-03  eta: 14:59:32  time: 4.3813  data_time: 3.7277  memory: 19734  loss: 3.8227  loss_prob: 2.4578  loss_thr: 0.8749  loss_db: 0.4900
2023/11/14 20:07:23 - mmengine - INFO - Epoch(train)   [80][15/16]  lr: 7.0000e-03  eta: 14:56:27  time: 0.5804  data_time: 0.0098  memory: 19734  loss: 3.7931  loss_prob: 2.4214  loss_thr: 0.8919  loss_db: 0.4797
2023/11/14 20:07:24 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:07:24 - mmengine - INFO - Saving checkpoint at 80 epochs
2023/11/14 20:07:25 - mmengine - INFO - Epoch(val)   [80][  5/125]    eta: 0:00:08  time: 0.0580  data_time: 0.0116  memory: 13005  
2023/11/14 20:07:26 - mmengine - INFO - Epoch(val)   [80][ 10/125]    eta: 0:00:06  time: 0.0554  data_time: 0.0120  memory: 2920  
2023/11/14 20:07:26 - mmengine - INFO - Epoch(val)   [80][ 15/125]    eta: 0:00:05  time: 0.0435  data_time: 0.0025  memory: 2920  
2023/11/14 20:07:26 - mmengine - INFO - Epoch(val)   [80][ 20/125]    eta: 0:00:05  time: 0.0434  data_time: 0.0033  memory: 2920  
2023/11/14 20:07:26 - mmengine - INFO - Epoch(val)   [80][ 25/125]    eta: 0:00:05  time: 0.0489  data_time: 0.0080  memory: 2920  
2023/11/14 20:07:27 - mmengine - INFO - Epoch(val)   [80][ 30/125]    eta: 0:00:04  time: 0.0521  data_time: 0.0084  memory: 2920  
2023/11/14 20:07:27 - mmengine - INFO - Epoch(val)   [80][ 35/125]    eta: 0:00:04  time: 0.0483  data_time: 0.0048  memory: 2920  
2023/11/14 20:07:27 - mmengine - INFO - Epoch(val)   [80][ 40/125]    eta: 0:00:04  time: 0.0491  data_time: 0.0038  memory: 2920  
2023/11/14 20:07:27 - mmengine - INFO - Epoch(val)   [80][ 45/125]    eta: 0:00:03  time: 0.0499  data_time: 0.0036  memory: 2920  
2023/11/14 20:07:27 - mmengine - INFO - Epoch(val)   [80][ 50/125]    eta: 0:00:03  time: 0.0464  data_time: 0.0035  memory: 2920  
2023/11/14 20:07:28 - mmengine - INFO - Epoch(val)   [80][ 55/125]    eta: 0:00:03  time: 0.0455  data_time: 0.0034  memory: 2920  
2023/11/14 20:07:28 - mmengine - INFO - Epoch(val)   [80][ 60/125]    eta: 0:00:03  time: 0.0473  data_time: 0.0043  memory: 2920  
2023/11/14 20:07:28 - mmengine - INFO - Epoch(val)   [80][ 65/125]    eta: 0:00:02  time: 0.0476  data_time: 0.0035  memory: 2920  
2023/11/14 20:07:28 - mmengine - INFO - Epoch(val)   [80][ 70/125]    eta: 0:00:02  time: 0.0477  data_time: 0.0032  memory: 2920  
2023/11/14 20:07:29 - mmengine - INFO - Epoch(val)   [80][ 75/125]    eta: 0:00:02  time: 0.0487  data_time: 0.0037  memory: 2920  
2023/11/14 20:07:29 - mmengine - INFO - Epoch(val)   [80][ 80/125]    eta: 0:00:02  time: 0.0476  data_time: 0.0025  memory: 2920  
2023/11/14 20:07:29 - mmengine - INFO - Epoch(val)   [80][ 85/125]    eta: 0:00:01  time: 0.0476  data_time: 0.0023  memory: 2920  
2023/11/14 20:07:29 - mmengine - INFO - Epoch(val)   [80][ 90/125]    eta: 0:00:01  time: 0.0527  data_time: 0.0032  memory: 2920  
2023/11/14 20:07:30 - mmengine - INFO - Epoch(val)   [80][ 95/125]    eta: 0:00:01  time: 0.0546  data_time: 0.0038  memory: 2920  
2023/11/14 20:07:30 - mmengine - INFO - Epoch(val)   [80][100/125]    eta: 0:00:01  time: 0.0492  data_time: 0.0029  memory: 2920  
2023/11/14 20:07:30 - mmengine - INFO - Epoch(val)   [80][105/125]    eta: 0:00:00  time: 0.0431  data_time: 0.0017  memory: 2920  
2023/11/14 20:07:30 - mmengine - INFO - Epoch(val)   [80][110/125]    eta: 0:00:00  time: 0.0432  data_time: 0.0017  memory: 2920  
2023/11/14 20:07:31 - mmengine - INFO - Epoch(val)   [80][115/125]    eta: 0:00:00  time: 0.0442  data_time: 0.0017  memory: 2920  
2023/11/14 20:07:31 - mmengine - INFO - Epoch(val)   [80][120/125]    eta: 0:00:00  time: 0.0427  data_time: 0.0016  memory: 2920  
2023/11/14 20:07:31 - mmengine - INFO - Epoch(val)   [80][125/125]    eta: 0:00:00  time: 0.0439  data_time: 0.0015  memory: 2920  
2023/11/14 20:07:31 - mmengine - INFO - Evaluating hmean-iou...
2023/11/14 20:07:31 - mmengine - INFO - prediction score threshold: 0.30, recall: 0.3438, precision: 0.2337, hmean: 0.2783

2023/11/14 20:07:31 - mmengine - INFO - prediction score threshold: 0.40, recall: 0.3418, precision: 0.3878, hmean: 0.3634

2023/11/14 20:07:31 - mmengine - INFO - prediction score threshold: 0.50, recall: 0.2990, precision: 0.5535, hmean: 0.3882

2023/11/14 20:07:31 - mmengine - INFO - prediction score threshold: 0.60, recall: 0.0573, precision: 0.6685, hmean: 0.1055

2023/11/14 20:07:31 - mmengine - INFO - prediction score threshold: 0.70, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 20:07:31 - mmengine - INFO - prediction score threshold: 0.80, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 20:07:31 - mmengine - INFO - prediction score threshold: 0.90, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 20:07:31 - mmengine - INFO - Epoch(val) [80][125/125]    icdar/precision: 0.5535  icdar/recall: 0.2990  icdar/hmean: 0.3882  data_time: 0.0041  time: 0.0481
2023/11/14 20:08:13 - mmengine - INFO - Epoch(train)   [81][ 5/16]  lr: 7.0000e-03  eta: 15:01:43  time: 4.4315  data_time: 3.8291  memory: 19734  loss: 3.6805  loss_prob: 2.3615  loss_thr: 0.8726  loss_db: 0.4465
2023/11/14 20:08:16 - mmengine - INFO - Epoch(train)   [81][10/16]  lr: 7.0000e-03  eta: 14:58:39  time: 4.4520  data_time: 3.8282  memory: 19734  loss: 3.6522  loss_prob: 2.3510  loss_thr: 0.8565  loss_db: 0.4446
2023/11/14 20:08:18 - mmengine - INFO - Epoch(train)   [81][15/16]  lr: 7.0000e-03  eta: 14:55:36  time: 0.5847  data_time: 0.0033  memory: 19734  loss: 3.5945  loss_prob: 2.2931  loss_thr: 0.8723  loss_db: 0.4292
2023/11/14 20:08:19 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:09:00 - mmengine - INFO - Epoch(train)   [82][ 5/16]  lr: 7.0000e-03  eta: 15:00:35  time: 4.3374  data_time: 3.6934  memory: 19734  loss: 3.6256  loss_prob: 2.3064  loss_thr: 0.8785  loss_db: 0.4407
2023/11/14 20:09:02 - mmengine - INFO - Epoch(train)   [82][10/16]  lr: 7.0000e-03  eta: 14:57:33  time: 4.3519  data_time: 3.6955  memory: 19734  loss: 3.7132  loss_prob: 2.3687  loss_thr: 0.8787  loss_db: 0.4659
2023/11/14 20:09:05 - mmengine - INFO - Epoch(train)   [82][15/16]  lr: 7.0000e-03  eta: 14:54:32  time: 0.5830  data_time: 0.0062  memory: 19734  loss: 3.6300  loss_prob: 2.3279  loss_thr: 0.8529  loss_db: 0.4492
2023/11/14 20:09:06 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:09:47 - mmengine - INFO - Epoch(train)   [83][ 5/16]  lr: 7.0000e-03  eta: 14:59:35  time: 4.3998  data_time: 3.8322  memory: 19734  loss: 3.6253  loss_prob: 2.3441  loss_thr: 0.8478  loss_db: 0.4333
2023/11/14 20:09:50 - mmengine - INFO - Epoch(train)   [83][10/16]  lr: 7.0000e-03  eta: 14:56:35  time: 4.4082  data_time: 3.8314  memory: 19734  loss: 3.6987  loss_prob: 2.3950  loss_thr: 0.8551  loss_db: 0.4485
2023/11/14 20:09:53 - mmengine - INFO - Epoch(train)   [83][15/16]  lr: 7.0000e-03  eta: 14:53:36  time: 0.5737  data_time: 0.0035  memory: 19734  loss: 3.6044  loss_prob: 2.3217  loss_thr: 0.8408  loss_db: 0.4418
2023/11/14 20:09:53 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:10:35 - mmengine - INFO - Epoch(train)   [84][ 5/16]  lr: 7.0000e-03  eta: 14:58:36  time: 4.4099  data_time: 3.7918  memory: 19734  loss: 3.7406  loss_prob: 2.4332  loss_thr: 0.8532  loss_db: 0.4541
2023/11/14 20:10:37 - mmengine - INFO - Epoch(train)   [84][10/16]  lr: 7.0000e-03  eta: 14:55:38  time: 4.4207  data_time: 3.7918  memory: 19734  loss: 3.6644  loss_prob: 2.4000  loss_thr: 0.8236  loss_db: 0.4408
2023/11/14 20:10:40 - mmengine - INFO - Epoch(train)   [84][15/16]  lr: 7.0000e-03  eta: 14:52:41  time: 0.5730  data_time: 0.0042  memory: 19734  loss: 3.6061  loss_prob: 2.3186  loss_thr: 0.8418  loss_db: 0.4458
2023/11/14 20:10:41 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:11:23 - mmengine - INFO - Epoch(train)   [85][ 5/16]  lr: 7.0000e-03  eta: 14:57:57  time: 4.5521  data_time: 3.8860  memory: 19734  loss: 3.8988  loss_prob: 2.4653  loss_thr: 0.9205  loss_db: 0.5130
2023/11/14 20:11:26 - mmengine - INFO - Epoch(train)   [85][10/16]  lr: 7.0000e-03  eta: 14:55:01  time: 4.5719  data_time: 3.8861  memory: 19734  loss: 3.7077  loss_prob: 2.3602  loss_thr: 0.8837  loss_db: 0.4637
2023/11/14 20:11:29 - mmengine - INFO - Epoch(train)   [85][15/16]  lr: 7.0000e-03  eta: 14:52:06  time: 0.5776  data_time: 0.0042  memory: 19734  loss: 3.5248  loss_prob: 2.2446  loss_thr: 0.8626  loss_db: 0.4177
2023/11/14 20:11:30 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:11:30 - mmengine - INFO - Saving checkpoint at 85 epochs
2023/11/14 20:12:12 - mmengine - INFO - Epoch(train)   [86][ 5/16]  lr: 7.0000e-03  eta: 14:56:52  time: 4.3571  data_time: 3.8007  memory: 19734  loss: 3.6609  loss_prob: 2.3252  loss_thr: 0.8765  loss_db: 0.4593
2023/11/14 20:12:15 - mmengine - INFO - Epoch(train)   [86][10/16]  lr: 7.0000e-03  eta: 14:54:00  time: 4.3849  data_time: 3.8012  memory: 19734  loss: 3.5166  loss_prob: 2.2449  loss_thr: 0.8484  loss_db: 0.4234
2023/11/14 20:12:18 - mmengine - INFO - Epoch(train)   [86][15/16]  lr: 7.0000e-03  eta: 14:51:08  time: 0.5907  data_time: 0.0061  memory: 19734  loss: 3.4943  loss_prob: 2.2540  loss_thr: 0.8279  loss_db: 0.4124
2023/11/14 20:12:18 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:13:00 - mmengine - INFO - Epoch(train)   [87][ 5/16]  lr: 7.0000e-03  eta: 14:56:06  time: 4.4814  data_time: 3.9167  memory: 19734  loss: 3.9087  loss_prob: 2.4930  loss_thr: 0.8952  loss_db: 0.5205
2023/11/14 20:13:03 - mmengine - INFO - Epoch(train)   [87][10/16]  lr: 7.0000e-03  eta: 14:53:14  time: 4.5022  data_time: 3.9196  memory: 19734  loss: 3.9981  loss_prob: 2.5383  loss_thr: 0.9180  loss_db: 0.5418
2023/11/14 20:13:06 - mmengine - INFO - Epoch(train)   [87][15/16]  lr: 7.0000e-03  eta: 14:50:24  time: 0.5876  data_time: 0.0067  memory: 19734  loss: 3.6592  loss_prob: 2.3459  loss_thr: 0.8574  loss_db: 0.4559
2023/11/14 20:13:07 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:13:48 - mmengine - INFO - Epoch(train)   [88][ 5/16]  lr: 7.0000e-03  eta: 14:55:08  time: 4.4036  data_time: 3.8293  memory: 19734  loss: 3.6930  loss_prob: 2.3656  loss_thr: 0.8674  loss_db: 0.4600
2023/11/14 20:13:51 - mmengine - INFO - Epoch(train)   [88][10/16]  lr: 7.0000e-03  eta: 14:52:18  time: 4.4122  data_time: 3.8290  memory: 19734  loss: 3.6331  loss_prob: 2.3170  loss_thr: 0.8676  loss_db: 0.4485
2023/11/14 20:13:54 - mmengine - INFO - Epoch(train)   [88][15/16]  lr: 7.0000e-03  eta: 14:49:29  time: 0.5747  data_time: 0.0042  memory: 19734  loss: 3.4945  loss_prob: 2.2410  loss_thr: 0.8374  loss_db: 0.4161
2023/11/14 20:13:54 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:14:36 - mmengine - INFO - Epoch(train)   [89][ 5/16]  lr: 7.0000e-03  eta: 14:54:12  time: 4.4173  data_time: 3.5200  memory: 19734  loss: 3.3695  loss_prob: 2.1464  loss_thr: 0.8406  loss_db: 0.3825
2023/11/14 20:14:38 - mmengine - INFO - Epoch(train)   [89][10/16]  lr: 7.0000e-03  eta: 14:51:25  time: 4.4456  data_time: 3.5244  memory: 19734  loss: 3.5845  loss_prob: 2.2870  loss_thr: 0.8505  loss_db: 0.4469
2023/11/14 20:14:41 - mmengine - INFO - Epoch(train)   [89][15/16]  lr: 7.0000e-03  eta: 14:48:38  time: 0.5827  data_time: 0.0077  memory: 19734  loss: 3.6123  loss_prob: 2.3211  loss_thr: 0.8407  loss_db: 0.4506
2023/11/14 20:14:42 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:15:23 - mmengine - INFO - Epoch(train)   [90][ 5/16]  lr: 7.0000e-03  eta: 14:53:18  time: 4.4303  data_time: 3.8356  memory: 19734  loss: 3.4372  loss_prob: 2.1927  loss_thr: 0.8540  loss_db: 0.3905
2023/11/14 20:15:26 - mmengine - INFO - Epoch(train)   [90][10/16]  lr: 7.0000e-03  eta: 14:50:33  time: 4.4602  data_time: 3.8399  memory: 19734  loss: 3.5685  loss_prob: 2.2628  loss_thr: 0.8760  loss_db: 0.4298
2023/11/14 20:15:29 - mmengine - INFO - Epoch(train)   [90][15/16]  lr: 7.0000e-03  eta: 14:47:49  time: 0.5884  data_time: 0.0088  memory: 19734  loss: 3.7273  loss_prob: 2.3927  loss_thr: 0.8579  loss_db: 0.4767
2023/11/14 20:15:30 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:15:30 - mmengine - INFO - Saving checkpoint at 90 epochs
2023/11/14 20:16:11 - mmengine - INFO - Epoch(train)   [91][ 5/16]  lr: 7.0000e-03  eta: 14:52:02  time: 4.2341  data_time: 3.5341  memory: 19734  loss: 3.6550  loss_prob: 2.3437  loss_thr: 0.8649  loss_db: 0.4465
2023/11/14 20:16:14 - mmengine - INFO - Epoch(train)   [91][10/16]  lr: 7.0000e-03  eta: 14:49:17  time: 4.2543  data_time: 3.5339  memory: 19734  loss: 3.4808  loss_prob: 2.2222  loss_thr: 0.8528  loss_db: 0.4058
2023/11/14 20:16:16 - mmengine - INFO - Epoch(train)   [91][15/16]  lr: 7.0000e-03  eta: 14:46:34  time: 0.5726  data_time: 0.0032  memory: 19734  loss: 3.4177  loss_prob: 2.1824  loss_thr: 0.8417  loss_db: 0.3936
2023/11/14 20:16:17 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:16:58 - mmengine - INFO - Epoch(train)   [92][ 5/16]  lr: 7.0000e-03  eta: 14:50:59  time: 4.3561  data_time: 3.7937  memory: 19734  loss: 3.3367  loss_prob: 2.1069  loss_thr: 0.8557  loss_db: 0.3741
2023/11/14 20:17:00 - mmengine - INFO - Epoch(train)   [92][10/16]  lr: 7.0000e-03  eta: 14:48:15  time: 4.3709  data_time: 3.7977  memory: 19734  loss: 3.3333  loss_prob: 2.1136  loss_thr: 0.8421  loss_db: 0.3776
2023/11/14 20:17:03 - mmengine - INFO - Epoch(train)   [92][15/16]  lr: 7.0000e-03  eta: 14:45:34  time: 0.5705  data_time: 0.0091  memory: 19734  loss: 3.5615  loss_prob: 2.2838  loss_thr: 0.8511  loss_db: 0.4266
2023/11/14 20:17:04 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:17:46 - mmengine - INFO - Epoch(train)   [93][ 5/16]  lr: 7.0000e-03  eta: 14:50:08  time: 4.4612  data_time: 3.8574  memory: 19734  loss: 3.5453  loss_prob: 2.3002  loss_thr: 0.8127  loss_db: 0.4323
2023/11/14 20:17:49 - mmengine - INFO - Epoch(train)   [93][10/16]  lr: 7.0000e-03  eta: 14:47:27  time: 4.4802  data_time: 3.8568  memory: 19734  loss: 3.5744  loss_prob: 2.2906  loss_thr: 0.8408  loss_db: 0.4431
2023/11/14 20:17:51 - mmengine - INFO - Epoch(train)   [93][15/16]  lr: 7.0000e-03  eta: 14:44:47  time: 0.5713  data_time: 0.0033  memory: 19734  loss: 3.6365  loss_prob: 2.3167  loss_thr: 0.8661  loss_db: 0.4536
2023/11/14 20:17:52 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:18:33 - mmengine - INFO - Epoch(train)   [94][ 5/16]  lr: 7.0000e-03  eta: 14:49:10  time: 4.3954  data_time: 3.7080  memory: 19734  loss: 3.7006  loss_prob: 2.3925  loss_thr: 0.8559  loss_db: 0.4522
2023/11/14 20:18:36 - mmengine - INFO - Epoch(train)   [94][10/16]  lr: 7.0000e-03  eta: 14:46:32  time: 4.4199  data_time: 3.7131  memory: 19734  loss: 3.7153  loss_prob: 2.3934  loss_thr: 0.8624  loss_db: 0.4596
2023/11/14 20:18:39 - mmengine - INFO - Epoch(train)   [94][15/16]  lr: 7.0000e-03  eta: 14:43:54  time: 0.5810  data_time: 0.0099  memory: 19734  loss: 3.7274  loss_prob: 2.3834  loss_thr: 0.8620  loss_db: 0.4820
2023/11/14 20:18:39 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:19:21 - mmengine - INFO - Epoch(train)   [95][ 5/16]  lr: 7.0000e-03  eta: 14:48:15  time: 4.4111  data_time: 3.7641  memory: 19734  loss: 3.6323  loss_prob: 2.3386  loss_thr: 0.8404  loss_db: 0.4533
2023/11/14 20:19:24 - mmengine - INFO - Epoch(train)   [95][10/16]  lr: 7.0000e-03  eta: 14:45:38  time: 4.4301  data_time: 3.7637  memory: 19734  loss: 3.6624  loss_prob: 2.3661  loss_thr: 0.8334  loss_db: 0.4629
2023/11/14 20:19:26 - mmengine - INFO - Epoch(train)   [95][15/16]  lr: 7.0000e-03  eta: 14:43:01  time: 0.5768  data_time: 0.0044  memory: 19734  loss: 3.5389  loss_prob: 2.2895  loss_thr: 0.8142  loss_db: 0.4352
2023/11/14 20:19:27 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:19:27 - mmengine - INFO - Saving checkpoint at 95 epochs
2023/11/14 20:20:08 - mmengine - INFO - Epoch(train)   [96][ 5/16]  lr: 7.0000e-03  eta: 14:47:04  time: 4.2740  data_time: 3.7127  memory: 19734  loss: 3.4410  loss_prob: 2.2133  loss_thr: 0.8262  loss_db: 0.4015
2023/11/14 20:20:11 - mmengine - INFO - Epoch(train)   [96][10/16]  lr: 7.0000e-03  eta: 14:44:29  time: 4.3020  data_time: 3.7144  memory: 19734  loss: 3.4372  loss_prob: 2.2094  loss_thr: 0.8240  loss_db: 0.4039
2023/11/14 20:20:14 - mmengine - INFO - Epoch(train)   [96][15/16]  lr: 7.0000e-03  eta: 14:41:55  time: 0.5859  data_time: 0.0051  memory: 19734  loss: 3.6563  loss_prob: 2.3304  loss_thr: 0.8663  loss_db: 0.4597
2023/11/14 20:20:14 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:20:56 - mmengine - INFO - Epoch(train)   [97][ 5/16]  lr: 7.0000e-03  eta: 14:46:07  time: 4.3855  data_time: 3.8140  memory: 19734  loss: 3.6913  loss_prob: 2.3659  loss_thr: 0.8585  loss_db: 0.4670
2023/11/14 20:20:59 - mmengine - INFO - Epoch(train)   [97][10/16]  lr: 7.0000e-03  eta: 14:43:33  time: 4.4020  data_time: 3.8139  memory: 19734  loss: 3.5594  loss_prob: 2.3056  loss_thr: 0.8296  loss_db: 0.4242
2023/11/14 20:21:01 - mmengine - INFO - Epoch(train)   [97][15/16]  lr: 7.0000e-03  eta: 14:41:00  time: 0.5844  data_time: 0.0045  memory: 19734  loss: 3.5800  loss_prob: 2.2988  loss_thr: 0.8535  loss_db: 0.4277
2023/11/14 20:21:02 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:21:43 - mmengine - INFO - Epoch(train)   [98][ 5/16]  lr: 7.0000e-03  eta: 14:45:09  time: 4.3818  data_time: 3.7385  memory: 19734  loss: 3.5242  loss_prob: 2.2492  loss_thr: 0.8516  loss_db: 0.4234
2023/11/14 20:21:46 - mmengine - INFO - Epoch(train)   [98][10/16]  lr: 7.0000e-03  eta: 14:42:36  time: 4.4001  data_time: 3.7393  memory: 19734  loss: 3.5354  loss_prob: 2.2692  loss_thr: 0.8389  loss_db: 0.4273
2023/11/14 20:21:49 - mmengine - INFO - Epoch(train)   [98][15/16]  lr: 7.0000e-03  eta: 14:40:05  time: 0.5787  data_time: 0.0064  memory: 19734  loss: 3.4971  loss_prob: 2.2598  loss_thr: 0.8187  loss_db: 0.4187
2023/11/14 20:21:49 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:22:32 - mmengine - INFO - Epoch(train)   [99][ 5/16]  lr: 7.0000e-03  eta: 14:44:28  time: 4.5313  data_time: 3.9712  memory: 19734  loss: 3.5228  loss_prob: 2.2464  loss_thr: 0.8573  loss_db: 0.4191
2023/11/14 20:22:35 - mmengine - INFO - Epoch(train)   [99][10/16]  lr: 7.0000e-03  eta: 14:41:56  time: 4.5483  data_time: 3.9702  memory: 19734  loss: 3.4955  loss_prob: 2.2341  loss_thr: 0.8423  loss_db: 0.4192
2023/11/14 20:22:37 - mmengine - INFO - Epoch(train)   [99][15/16]  lr: 7.0000e-03  eta: 14:39:26  time: 0.5750  data_time: 0.0035  memory: 19734  loss: 3.3896  loss_prob: 2.1525  loss_thr: 0.8405  loss_db: 0.3966
2023/11/14 20:22:38 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:23:19 - mmengine - INFO - Epoch(train)  [100][ 5/16]  lr: 7.0000e-03  eta: 14:43:32  time: 4.4027  data_time: 3.7069  memory: 19734  loss: 3.5038  loss_prob: 2.2324  loss_thr: 0.8496  loss_db: 0.4217
2023/11/14 20:23:22 - mmengine - INFO - Epoch(train)  [100][10/16]  lr: 7.0000e-03  eta: 14:41:02  time: 4.4158  data_time: 3.7071  memory: 19734  loss: 3.5857  loss_prob: 2.3012  loss_thr: 0.8396  loss_db: 0.4449
2023/11/14 20:23:25 - mmengine - INFO - Epoch(train)  [100][15/16]  lr: 7.0000e-03  eta: 14:38:34  time: 0.5796  data_time: 0.0036  memory: 19734  loss: 3.6434  loss_prob: 2.3485  loss_thr: 0.8453  loss_db: 0.4495
2023/11/14 20:23:25 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:23:25 - mmengine - INFO - Saving checkpoint at 100 epochs
2023/11/14 20:23:27 - mmengine - INFO - Epoch(val)  [100][  5/125]    eta: 0:00:07  time: 0.0561  data_time: 0.0124  memory: 13005  
2023/11/14 20:23:27 - mmengine - INFO - Epoch(val)  [100][ 10/125]    eta: 0:00:06  time: 0.0549  data_time: 0.0131  memory: 2920  
2023/11/14 20:23:28 - mmengine - INFO - Epoch(val)  [100][ 15/125]    eta: 0:00:05  time: 0.0441  data_time: 0.0025  memory: 2920  
2023/11/14 20:23:28 - mmengine - INFO - Epoch(val)  [100][ 20/125]    eta: 0:00:05  time: 0.0473  data_time: 0.0059  memory: 2920  
2023/11/14 20:23:28 - mmengine - INFO - Epoch(val)  [100][ 25/125]    eta: 0:00:05  time: 0.0490  data_time: 0.0064  memory: 2920  
2023/11/14 20:23:28 - mmengine - INFO - Epoch(val)  [100][ 30/125]    eta: 0:00:04  time: 0.0472  data_time: 0.0025  memory: 2920  
2023/11/14 20:23:28 - mmengine - INFO - Epoch(val)  [100][ 35/125]    eta: 0:00:04  time: 0.0457  data_time: 0.0022  memory: 2920  
2023/11/14 20:23:29 - mmengine - INFO - Epoch(val)  [100][ 40/125]    eta: 0:00:04  time: 0.0472  data_time: 0.0031  memory: 2920  
2023/11/14 20:23:29 - mmengine - INFO - Epoch(val)  [100][ 45/125]    eta: 0:00:03  time: 0.0501  data_time: 0.0039  memory: 2920  
2023/11/14 20:23:29 - mmengine - INFO - Epoch(val)  [100][ 50/125]    eta: 0:00:03  time: 0.0503  data_time: 0.0047  memory: 2920  
2023/11/14 20:23:29 - mmengine - INFO - Epoch(val)  [100][ 55/125]    eta: 0:00:03  time: 0.0468  data_time: 0.0045  memory: 2920  
2023/11/14 20:23:30 - mmengine - INFO - Epoch(val)  [100][ 60/125]    eta: 0:00:03  time: 0.0455  data_time: 0.0043  memory: 2920  
2023/11/14 20:23:30 - mmengine - INFO - Epoch(val)  [100][ 65/125]    eta: 0:00:02  time: 0.0487  data_time: 0.0040  memory: 2920  
2023/11/14 20:23:30 - mmengine - INFO - Epoch(val)  [100][ 70/125]    eta: 0:00:02  time: 0.0487  data_time: 0.0035  memory: 2920  
2023/11/14 20:23:30 - mmengine - INFO - Epoch(val)  [100][ 75/125]    eta: 0:00:02  time: 0.0466  data_time: 0.0027  memory: 2920  
2023/11/14 20:23:31 - mmengine - INFO - Epoch(val)  [100][ 80/125]    eta: 0:00:02  time: 0.0452  data_time: 0.0019  memory: 2920  
2023/11/14 20:23:31 - mmengine - INFO - Epoch(val)  [100][ 85/125]    eta: 0:00:01  time: 0.0458  data_time: 0.0019  memory: 2920  
2023/11/14 20:23:31 - mmengine - INFO - Epoch(val)  [100][ 90/125]    eta: 0:00:01  time: 0.0514  data_time: 0.0023  memory: 2920  
2023/11/14 20:23:31 - mmengine - INFO - Epoch(val)  [100][ 95/125]    eta: 0:00:01  time: 0.0522  data_time: 0.0023  memory: 2920  
2023/11/14 20:23:32 - mmengine - INFO - Epoch(val)  [100][100/125]    eta: 0:00:01  time: 0.0472  data_time: 0.0017  memory: 2920  
2023/11/14 20:23:32 - mmengine - INFO - Epoch(val)  [100][105/125]    eta: 0:00:00  time: 0.0429  data_time: 0.0016  memory: 2920  
2023/11/14 20:23:32 - mmengine - INFO - Epoch(val)  [100][110/125]    eta: 0:00:00  time: 0.0426  data_time: 0.0016  memory: 2920  
2023/11/14 20:23:32 - mmengine - INFO - Epoch(val)  [100][115/125]    eta: 0:00:00  time: 0.0443  data_time: 0.0016  memory: 2920  
2023/11/14 20:23:32 - mmengine - INFO - Epoch(val)  [100][120/125]    eta: 0:00:00  time: 0.0425  data_time: 0.0015  memory: 2920  
2023/11/14 20:23:33 - mmengine - INFO - Epoch(val)  [100][125/125]    eta: 0:00:00  time: 0.0436  data_time: 0.0014  memory: 2920  
2023/11/14 20:23:33 - mmengine - INFO - Evaluating hmean-iou...
2023/11/14 20:23:33 - mmengine - INFO - prediction score threshold: 0.30, recall: 0.4078, precision: 0.3049, hmean: 0.3489

2023/11/14 20:23:33 - mmengine - INFO - prediction score threshold: 0.40, recall: 0.4054, precision: 0.4446, hmean: 0.4241

2023/11/14 20:23:33 - mmengine - INFO - prediction score threshold: 0.50, recall: 0.3741, precision: 0.5751, hmean: 0.4533

2023/11/14 20:23:33 - mmengine - INFO - prediction score threshold: 0.60, recall: 0.2215, precision: 0.6735, hmean: 0.3333

2023/11/14 20:23:33 - mmengine - INFO - prediction score threshold: 0.70, recall: 0.0010, precision: 0.6667, hmean: 0.0019

2023/11/14 20:23:33 - mmengine - INFO - prediction score threshold: 0.80, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 20:23:33 - mmengine - INFO - prediction score threshold: 0.90, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 20:23:33 - mmengine - INFO - Epoch(val) [100][125/125]    icdar/precision: 0.5751  icdar/recall: 0.3741  icdar/hmean: 0.4533  data_time: 0.0037  time: 0.0475
2023/11/14 20:24:15 - mmengine - INFO - Epoch(train)  [101][ 5/16]  lr: 7.0000e-03  eta: 14:42:43  time: 4.4729  data_time: 3.8223  memory: 19734  loss: 3.5119  loss_prob: 2.2630  loss_thr: 0.8384  loss_db: 0.4105
2023/11/14 20:24:18 - mmengine - INFO - Epoch(train)  [101][10/16]  lr: 7.0000e-03  eta: 14:40:16  time: 4.4860  data_time: 3.8233  memory: 19734  loss: 3.5519  loss_prob: 2.2916  loss_thr: 0.8395  loss_db: 0.4208
2023/11/14 20:24:20 - mmengine - INFO - Epoch(train)  [101][15/16]  lr: 7.0000e-03  eta: 14:37:48  time: 0.5776  data_time: 0.0044  memory: 19734  loss: 3.5737  loss_prob: 2.2997  loss_thr: 0.8375  loss_db: 0.4365
2023/11/14 20:24:21 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:25:03 - mmengine - INFO - Epoch(train)  [102][ 5/16]  lr: 6.9943e-03  eta: 14:41:57  time: 4.4828  data_time: 3.8576  memory: 19734  loss: 3.5312  loss_prob: 2.2879  loss_thr: 0.8169  loss_db: 0.4263
2023/11/14 20:25:06 - mmengine - INFO - Epoch(train)  [102][10/16]  lr: 6.9943e-03  eta: 14:39:30  time: 4.5015  data_time: 3.8611  memory: 19734  loss: 3.6010  loss_prob: 2.3398  loss_thr: 0.8193  loss_db: 0.4419
2023/11/14 20:25:09 - mmengine - INFO - Epoch(train)  [102][15/16]  lr: 6.9943e-03  eta: 14:37:04  time: 0.5772  data_time: 0.0071  memory: 19734  loss: 3.5473  loss_prob: 2.2750  loss_thr: 0.8349  loss_db: 0.4374
2023/11/14 20:25:09 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:25:51 - mmengine - INFO - Epoch(train)  [103][ 5/16]  lr: 6.9885e-03  eta: 14:41:07  time: 4.4560  data_time: 3.8953  memory: 19734  loss: 3.6279  loss_prob: 2.3232  loss_thr: 0.8497  loss_db: 0.4550
2023/11/14 20:25:54 - mmengine - INFO - Epoch(train)  [103][10/16]  lr: 6.9885e-03  eta: 14:38:42  time: 4.4795  data_time: 3.8961  memory: 19734  loss: 3.6668  loss_prob: 2.3289  loss_thr: 0.8759  loss_db: 0.4621
2023/11/14 20:25:57 - mmengine - INFO - Epoch(train)  [103][15/16]  lr: 6.9885e-03  eta: 14:36:18  time: 0.5820  data_time: 0.0054  memory: 19734  loss: 3.5951  loss_prob: 2.3012  loss_thr: 0.8529  loss_db: 0.4411
2023/11/14 20:25:57 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:26:40 - mmengine - INFO - Epoch(train)  [104][ 5/16]  lr: 6.9828e-03  eta: 14:40:24  time: 4.5144  data_time: 3.8267  memory: 19734  loss: 3.5594  loss_prob: 2.2898  loss_thr: 0.8351  loss_db: 0.4345
2023/11/14 20:26:43 - mmengine - INFO - Epoch(train)  [104][10/16]  lr: 6.9828e-03  eta: 14:38:00  time: 4.5296  data_time: 3.8255  memory: 19734  loss: 3.3571  loss_prob: 2.1630  loss_thr: 0.7983  loss_db: 0.3958
2023/11/14 20:26:45 - mmengine - INFO - Epoch(train)  [104][15/16]  lr: 6.9828e-03  eta: 14:35:38  time: 0.5795  data_time: 0.0043  memory: 19734  loss: 3.3771  loss_prob: 2.1843  loss_thr: 0.7977  loss_db: 0.3950
2023/11/14 20:26:46 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:27:28 - mmengine - INFO - Epoch(train)  [105][ 5/16]  lr: 6.9771e-03  eta: 14:39:37  time: 4.4846  data_time: 3.9069  memory: 19734  loss: 3.3223  loss_prob: 2.1280  loss_thr: 0.8123  loss_db: 0.3820
2023/11/14 20:27:31 - mmengine - INFO - Epoch(train)  [105][10/16]  lr: 6.9771e-03  eta: 14:37:15  time: 4.4953  data_time: 3.9058  memory: 19734  loss: 3.3911  loss_prob: 2.1670  loss_thr: 0.8222  loss_db: 0.4018
2023/11/14 20:27:34 - mmengine - INFO - Epoch(train)  [105][15/16]  lr: 6.9771e-03  eta: 14:34:53  time: 0.5721  data_time: 0.0031  memory: 19734  loss: 3.5597  loss_prob: 2.2700  loss_thr: 0.8454  loss_db: 0.4443
2023/11/14 20:27:34 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:27:34 - mmengine - INFO - Saving checkpoint at 105 epochs
2023/11/14 20:28:16 - mmengine - INFO - Epoch(train)  [106][ 5/16]  lr: 6.9713e-03  eta: 14:38:32  time: 4.3117  data_time: 3.7405  memory: 19734  loss: 3.3136  loss_prob: 2.1194  loss_thr: 0.8136  loss_db: 0.3806
2023/11/14 20:28:19 - mmengine - INFO - Epoch(train)  [106][10/16]  lr: 6.9713e-03  eta: 14:36:12  time: 4.3340  data_time: 3.7413  memory: 19734  loss: 3.2957  loss_prob: 2.1284  loss_thr: 0.7870  loss_db: 0.3803
2023/11/14 20:28:22 - mmengine - INFO - Epoch(train)  [106][15/16]  lr: 6.9713e-03  eta: 14:33:52  time: 0.5835  data_time: 0.0055  memory: 19734  loss: 3.4395  loss_prob: 2.2033  loss_thr: 0.8310  loss_db: 0.4052
2023/11/14 20:28:22 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:29:04 - mmengine - INFO - Epoch(train)  [107][ 5/16]  lr: 6.9656e-03  eta: 14:37:43  time: 4.4605  data_time: 3.7297  memory: 19734  loss: 3.4020  loss_prob: 2.1682  loss_thr: 0.8405  loss_db: 0.3932
2023/11/14 20:29:07 - mmengine - INFO - Epoch(train)  [107][10/16]  lr: 6.9656e-03  eta: 14:35:24  time: 4.4750  data_time: 3.7282  memory: 19734  loss: 3.2892  loss_prob: 2.1194  loss_thr: 0.7926  loss_db: 0.3772
2023/11/14 20:29:10 - mmengine - INFO - Epoch(train)  [107][15/16]  lr: 6.9656e-03  eta: 14:33:05  time: 0.5802  data_time: 0.0043  memory: 19734  loss: 3.3658  loss_prob: 2.1472  loss_thr: 0.8265  loss_db: 0.3921
2023/11/14 20:29:10 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:29:52 - mmengine - INFO - Epoch(train)  [108][ 5/16]  lr: 6.9599e-03  eta: 14:36:54  time: 4.4523  data_time: 3.8470  memory: 19734  loss: 3.4484  loss_prob: 2.1967  loss_thr: 0.8449  loss_db: 0.4067
2023/11/14 20:29:55 - mmengine - INFO - Epoch(train)  [108][10/16]  lr: 6.9599e-03  eta: 14:34:35  time: 4.4633  data_time: 3.8458  memory: 19734  loss: 3.4982  loss_prob: 2.2582  loss_thr: 0.8225  loss_db: 0.4175
2023/11/14 20:29:58 - mmengine - INFO - Epoch(train)  [108][15/16]  lr: 6.9599e-03  eta: 14:32:17  time: 0.5762  data_time: 0.0044  memory: 19734  loss: 3.5971  loss_prob: 2.2948  loss_thr: 0.8598  loss_db: 0.4425
2023/11/14 20:29:58 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:30:39 - mmengine - INFO - Epoch(train)  [109][ 5/16]  lr: 6.9541e-03  eta: 14:35:59  time: 4.4065  data_time: 3.8429  memory: 19734  loss: 3.5885  loss_prob: 2.2893  loss_thr: 0.8552  loss_db: 0.4439
2023/11/14 20:30:42 - mmengine - INFO - Epoch(train)  [109][10/16]  lr: 6.9541e-03  eta: 14:33:42  time: 4.4231  data_time: 3.8429  memory: 19734  loss: 3.4210  loss_prob: 2.2038  loss_thr: 0.8135  loss_db: 0.4037
2023/11/14 20:30:45 - mmengine - INFO - Epoch(train)  [109][15/16]  lr: 6.9541e-03  eta: 14:31:26  time: 0.5832  data_time: 0.0061  memory: 19734  loss: 3.3393  loss_prob: 2.1337  loss_thr: 0.8257  loss_db: 0.3800
2023/11/14 20:30:46 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:31:28 - mmengine - INFO - Epoch(train)  [110][ 5/16]  lr: 6.9484e-03  eta: 14:35:10  time: 4.4576  data_time: 3.8082  memory: 19734  loss: 3.4966  loss_prob: 2.2460  loss_thr: 0.8370  loss_db: 0.4136
2023/11/14 20:31:31 - mmengine - INFO - Epoch(train)  [110][10/16]  lr: 6.9484e-03  eta: 14:32:55  time: 4.4822  data_time: 3.8102  memory: 19734  loss: 3.4794  loss_prob: 2.2375  loss_thr: 0.8330  loss_db: 0.4089
2023/11/14 20:31:33 - mmengine - INFO - Epoch(train)  [110][15/16]  lr: 6.9484e-03  eta: 14:30:39  time: 0.5809  data_time: 0.0065  memory: 19734  loss: 3.2118  loss_prob: 2.0523  loss_thr: 0.8029  loss_db: 0.3566
2023/11/14 20:31:34 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:31:34 - mmengine - INFO - Saving checkpoint at 110 epochs
2023/11/14 20:32:17 - mmengine - INFO - Epoch(train)  [111][ 5/16]  lr: 6.9426e-03  eta: 14:34:18  time: 4.4254  data_time: 3.8652  memory: 19734  loss: 3.2688  loss_prob: 2.0955  loss_thr: 0.7959  loss_db: 0.3774
2023/11/14 20:32:20 - mmengine - INFO - Epoch(train)  [111][10/16]  lr: 6.9426e-03  eta: 14:32:03  time: 4.4458  data_time: 3.8654  memory: 19734  loss: 3.5217  loss_prob: 2.2780  loss_thr: 0.8151  loss_db: 0.4286
2023/11/14 20:32:22 - mmengine - INFO - Epoch(train)  [111][15/16]  lr: 6.9426e-03  eta: 14:29:49  time: 0.5727  data_time: 0.0034  memory: 19734  loss: 3.5386  loss_prob: 2.2796  loss_thr: 0.8293  loss_db: 0.4298
2023/11/14 20:32:23 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:33:06 - mmengine - INFO - Epoch(train)  [112][ 5/16]  lr: 6.9369e-03  eta: 14:33:37  time: 4.5406  data_time: 3.9275  memory: 19734  loss: 3.4357  loss_prob: 2.1851  loss_thr: 0.8486  loss_db: 0.4020
2023/11/14 20:33:09 - mmengine - INFO - Epoch(train)  [112][10/16]  lr: 6.9369e-03  eta: 14:31:25  time: 4.5768  data_time: 3.9285  memory: 19734  loss: 3.3812  loss_prob: 2.1704  loss_thr: 0.8203  loss_db: 0.3905
2023/11/14 20:33:11 - mmengine - INFO - Epoch(train)  [112][15/16]  lr: 6.9369e-03  eta: 14:29:12  time: 0.5901  data_time: 0.0041  memory: 19734  loss: 3.3728  loss_prob: 2.1826  loss_thr: 0.7953  loss_db: 0.3950
2023/11/14 20:33:12 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:33:54 - mmengine - INFO - Epoch(train)  [113][ 5/16]  lr: 6.9312e-03  eta: 14:32:50  time: 4.4601  data_time: 3.7288  memory: 19734  loss: 3.4434  loss_prob: 2.2204  loss_thr: 0.8084  loss_db: 0.4146
2023/11/14 20:33:57 - mmengine - INFO - Epoch(train)  [113][10/16]  lr: 6.9312e-03  eta: 14:30:38  time: 4.4911  data_time: 3.7320  memory: 19734  loss: 3.5929  loss_prob: 2.3147  loss_thr: 0.8292  loss_db: 0.4490
2023/11/14 20:34:00 - mmengine - INFO - Epoch(train)  [113][15/16]  lr: 6.9312e-03  eta: 14:28:27  time: 0.5939  data_time: 0.0077  memory: 19734  loss: 3.7497  loss_prob: 2.4094  loss_thr: 0.8499  loss_db: 0.4904
2023/11/14 20:34:00 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:34:43 - mmengine - INFO - Epoch(train)  [114][ 5/16]  lr: 6.9254e-03  eta: 14:32:07  time: 4.5191  data_time: 3.9514  memory: 19734  loss: 3.6115  loss_prob: 2.3099  loss_thr: 0.8508  loss_db: 0.4509
2023/11/14 20:34:45 - mmengine - INFO - Epoch(train)  [114][10/16]  lr: 6.9254e-03  eta: 14:29:57  time: 4.5376  data_time: 3.9506  memory: 19734  loss: 3.4799  loss_prob: 2.2262  loss_thr: 0.8363  loss_db: 0.4174
2023/11/14 20:34:48 - mmengine - INFO - Epoch(train)  [114][15/16]  lr: 6.9254e-03  eta: 14:27:46  time: 0.5813  data_time: 0.0038  memory: 19734  loss: 3.4718  loss_prob: 2.2371  loss_thr: 0.8297  loss_db: 0.4050
2023/11/14 20:34:49 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:35:30 - mmengine - INFO - Epoch(train)  [115][ 5/16]  lr: 6.9197e-03  eta: 14:31:11  time: 4.3729  data_time: 3.7864  memory: 19734  loss: 3.5172  loss_prob: 2.2689  loss_thr: 0.8386  loss_db: 0.4098
2023/11/14 20:35:33 - mmengine - INFO - Epoch(train)  [115][10/16]  lr: 6.9197e-03  eta: 14:29:01  time: 4.3976  data_time: 3.7865  memory: 19734  loss: 3.4776  loss_prob: 2.2149  loss_thr: 0.8438  loss_db: 0.4190
2023/11/14 20:35:36 - mmengine - INFO - Epoch(train)  [115][15/16]  lr: 6.9197e-03  eta: 14:26:52  time: 0.5836  data_time: 0.0035  memory: 19734  loss: 3.3506  loss_prob: 2.1320  loss_thr: 0.8119  loss_db: 0.4068
2023/11/14 20:35:36 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:35:36 - mmengine - INFO - Saving checkpoint at 115 epochs
2023/11/14 20:36:18 - mmengine - INFO - Epoch(train)  [116][ 5/16]  lr: 6.9140e-03  eta: 14:30:09  time: 4.3210  data_time: 3.7468  memory: 19734  loss: 3.3788  loss_prob: 2.1721  loss_thr: 0.8026  loss_db: 0.4042
2023/11/14 20:36:21 - mmengine - INFO - Epoch(train)  [116][10/16]  lr: 6.9140e-03  eta: 14:28:01  time: 4.3404  data_time: 3.7512  memory: 19734  loss: 3.3143  loss_prob: 2.1273  loss_thr: 0.8015  loss_db: 0.3856
2023/11/14 20:36:24 - mmengine - INFO - Epoch(train)  [116][15/16]  lr: 6.9140e-03  eta: 14:25:52  time: 0.5814  data_time: 0.0079  memory: 19734  loss: 3.4060  loss_prob: 2.1627  loss_thr: 0.8470  loss_db: 0.3963
2023/11/14 20:36:24 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:37:07 - mmengine - INFO - Epoch(train)  [117][ 5/16]  lr: 6.9082e-03  eta: 14:29:32  time: 4.5800  data_time: 3.8450  memory: 19734  loss: 3.4416  loss_prob: 2.2029  loss_thr: 0.8286  loss_db: 0.4100
2023/11/14 20:37:10 - mmengine - INFO - Epoch(train)  [117][10/16]  lr: 6.9082e-03  eta: 14:27:25  time: 4.6123  data_time: 3.8490  memory: 19734  loss: 3.5703  loss_prob: 2.2893  loss_thr: 0.8443  loss_db: 0.4368
2023/11/14 20:37:13 - mmengine - INFO - Epoch(train)  [117][15/16]  lr: 6.9082e-03  eta: 14:25:18  time: 0.5955  data_time: 0.0084  memory: 19734  loss: 3.6028  loss_prob: 2.3099  loss_thr: 0.8524  loss_db: 0.4404
2023/11/14 20:37:14 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:37:56 - mmengine - INFO - Epoch(train)  [118][ 5/16]  lr: 6.9025e-03  eta: 14:28:48  time: 4.4980  data_time: 3.9001  memory: 19734  loss: 3.5589  loss_prob: 2.3023  loss_thr: 0.8173  loss_db: 0.4393
2023/11/14 20:37:59 - mmengine - INFO - Epoch(train)  [118][10/16]  lr: 6.9025e-03  eta: 14:26:42  time: 4.5212  data_time: 3.9043  memory: 19734  loss: 3.6020  loss_prob: 2.3231  loss_thr: 0.8422  loss_db: 0.4367
2023/11/14 20:38:02 - mmengine - INFO - Epoch(train)  [118][15/16]  lr: 6.9025e-03  eta: 14:24:36  time: 0.5924  data_time: 0.0086  memory: 19734  loss: 3.4296  loss_prob: 2.1856  loss_thr: 0.8487  loss_db: 0.3953
2023/11/14 20:38:02 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:38:44 - mmengine - INFO - Epoch(train)  [119][ 5/16]  lr: 6.8967e-03  eta: 14:28:02  time: 4.4831  data_time: 3.9183  memory: 19734  loss: 3.1226  loss_prob: 2.0024  loss_thr: 0.7842  loss_db: 0.3360
2023/11/14 20:38:47 - mmengine - INFO - Epoch(train)  [119][10/16]  lr: 6.8967e-03  eta: 14:25:56  time: 4.4937  data_time: 3.9182  memory: 19734  loss: 3.2565  loss_prob: 2.0905  loss_thr: 0.7963  loss_db: 0.3697
2023/11/14 20:38:50 - mmengine - INFO - Epoch(train)  [119][15/16]  lr: 6.8967e-03  eta: 14:23:51  time: 0.5793  data_time: 0.0033  memory: 19734  loss: 3.3954  loss_prob: 2.1810  loss_thr: 0.8180  loss_db: 0.3964
2023/11/14 20:38:50 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:39:32 - mmengine - INFO - Epoch(train)  [120][ 5/16]  lr: 6.8910e-03  eta: 14:27:11  time: 4.4423  data_time: 3.7513  memory: 19734  loss: 3.3745  loss_prob: 2.1712  loss_thr: 0.8145  loss_db: 0.3888
2023/11/14 20:39:35 - mmengine - INFO - Epoch(train)  [120][10/16]  lr: 6.8910e-03  eta: 14:25:06  time: 4.4545  data_time: 3.7520  memory: 19734  loss: 3.2979  loss_prob: 2.1188  loss_thr: 0.8029  loss_db: 0.3762
2023/11/14 20:39:38 - mmengine - INFO - Epoch(train)  [120][15/16]  lr: 6.8910e-03  eta: 14:23:02  time: 0.5768  data_time: 0.0041  memory: 19734  loss: 3.2304  loss_prob: 2.0733  loss_thr: 0.7914  loss_db: 0.3658
2023/11/14 20:39:38 - mmengine - INFO - Exp name: clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji_20231114_190235
2023/11/14 20:39:38 - mmengine - INFO - Saving checkpoint at 120 epochs
2023/11/14 20:39:40 - mmengine - INFO - Epoch(val)  [120][  5/125]    eta: 0:00:07  time: 0.0560  data_time: 0.0114  memory: 13005  
2023/11/14 20:39:40 - mmengine - INFO - Epoch(val)  [120][ 10/125]    eta: 0:00:06  time: 0.0542  data_time: 0.0120  memory: 2920  
2023/11/14 20:39:40 - mmengine - INFO - Epoch(val)  [120][ 15/125]    eta: 0:00:05  time: 0.0440  data_time: 0.0024  memory: 2920  
2023/11/14 20:39:41 - mmengine - INFO - Epoch(val)  [120][ 20/125]    eta: 0:00:05  time: 0.0466  data_time: 0.0053  memory: 2920  
2023/11/14 20:39:41 - mmengine - INFO - Epoch(val)  [120][ 25/125]    eta: 0:00:04  time: 0.0467  data_time: 0.0061  memory: 2920  
2023/11/14 20:39:41 - mmengine - INFO - Epoch(val)  [120][ 30/125]    eta: 0:00:04  time: 0.0468  data_time: 0.0049  memory: 2920  
2023/11/14 20:39:41 - mmengine - INFO - Epoch(val)  [120][ 35/125]    eta: 0:00:04  time: 0.0463  data_time: 0.0050  memory: 2920  
2023/11/14 20:39:42 - mmengine - INFO - Epoch(val)  [120][ 40/125]    eta: 0:00:04  time: 0.0447  data_time: 0.0033  memory: 2920  
2023/11/14 20:39:42 - mmengine - INFO - Epoch(val)  [120][ 45/125]    eta: 0:00:03  time: 0.0472  data_time: 0.0040  memory: 2920  
2023/11/14 20:39:42 - mmengine - INFO - Epoch(val)  [120][ 50/125]    eta: 0:00:03  time: 0.0448  data_time: 0.0033  memory: 2920  
2023/11/14 20:39:42 - mmengine - INFO - Epoch(val)  [120][ 55/125]    eta: 0:00:03  time: 0.0419  data_time: 0.0025  memory: 2920  
2023/11/14 20:39:43 - mmengine - INFO - Epoch(val)  [120][ 60/125]    eta: 0:00:03  time: 0.0459  data_time: 0.0057  memory: 2920  
2023/11/14 20:39:43 - mmengine - INFO - Epoch(val)  [120][ 65/125]    eta: 0:00:02  time: 0.0466  data_time: 0.0044  memory: 2920  
2023/11/14 20:39:43 - mmengine - INFO - Epoch(val)  [120][ 70/125]    eta: 0:00:02  time: 0.0450  data_time: 0.0022  memory: 2920  
2023/11/14 20:39:43 - mmengine - INFO - Epoch(val)  [120][ 75/125]    eta: 0:00:02  time: 0.0484  data_time: 0.0058  memory: 2920  
2023/11/14 20:39:43 - mmengine - INFO - Epoch(val)  [120][ 80/125]    eta: 0:00:02  time: 0.0470  data_time: 0.0055  memory: 2920  
2023/11/14 20:39:44 - mmengine - INFO - Epoch(val)  [120][ 85/125]    eta: 0:00:01  time: 0.0431  data_time: 0.0019  memory: 2920  
2023/11/14 20:39:44 - mmengine - INFO - Epoch(val)  [120][ 90/125]    eta: 0:00:01  time: 0.0467  data_time: 0.0014  memory: 2920  
2023/11/14 20:39:44 - mmengine - INFO - Epoch(val)  [120][ 95/125]    eta: 0:00:01  time: 0.0495  data_time: 0.0018  memory: 2920  
2023/11/14 20:39:44 - mmengine - INFO - Epoch(val)  [120][100/125]    eta: 0:00:01  time: 0.0467  data_time: 0.0018  memory: 2920  
2023/11/14 20:39:45 - mmengine - INFO - Epoch(val)  [120][105/125]    eta: 0:00:00  time: 0.0422  data_time: 0.0014  memory: 2920  
2023/11/14 20:39:45 - mmengine - INFO - Epoch(val)  [120][110/125]    eta: 0:00:00  time: 0.0429  data_time: 0.0015  memory: 2920  
2023/11/14 20:39:45 - mmengine - INFO - Epoch(val)  [120][115/125]    eta: 0:00:00  time: 0.0444  data_time: 0.0017  memory: 2920  
2023/11/14 20:39:45 - mmengine - INFO - Epoch(val)  [120][120/125]    eta: 0:00:00  time: 0.0422  data_time: 0.0017  memory: 2920  
2023/11/14 20:39:45 - mmengine - INFO - Epoch(val)  [120][125/125]    eta: 0:00:00  time: 0.0430  data_time: 0.0015  memory: 2920  
2023/11/14 20:39:45 - mmengine - INFO - Evaluating hmean-iou...
2023/11/14 20:39:45 - mmengine - INFO - prediction score threshold: 0.30, recall: 0.5320, precision: 0.4211, hmean: 0.4701

2023/11/14 20:39:45 - mmengine - INFO - prediction score threshold: 0.40, recall: 0.5315, precision: 0.5551, hmean: 0.5430

2023/11/14 20:39:45 - mmengine - INFO - prediction score threshold: 0.50, recall: 0.4983, precision: 0.6863, hmean: 0.5774

2023/11/14 20:39:45 - mmengine - INFO - prediction score threshold: 0.60, recall: 0.3235, precision: 0.8019, hmean: 0.4611

2023/11/14 20:39:45 - mmengine - INFO - prediction score threshold: 0.70, recall: 0.0029, precision: 0.6000, hmean: 0.0057

2023/11/14 20:39:45 - mmengine - INFO - prediction score threshold: 0.80, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 20:39:45 - mmengine - INFO - prediction score threshold: 0.90, recall: 0.0000, precision: 0.0000, hmean: 0.0000

2023/11/14 20:39:45 - mmengine - INFO - Epoch(val) [120][125/125]    icdar/precision: 0.6863  icdar/recall: 0.4983  icdar/hmean: 0.5774  data_time: 0.0039  time: 0.0461
2023/11/14 20:40:27 - mmengine - INFO - Epoch(train)  [121][ 5/16]  lr: 6.8852e-03  eta: 14:26:18  time: 4.4109  data_time: 3.7444  memory: 19734  loss: 3.1050  loss_prob: 1.9744  loss_thr: 0.7912  loss_db: 0.3393
