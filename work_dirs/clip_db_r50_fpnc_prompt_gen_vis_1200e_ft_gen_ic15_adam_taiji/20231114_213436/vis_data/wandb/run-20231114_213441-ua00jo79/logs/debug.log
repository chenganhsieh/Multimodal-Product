2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_setup.py:_flush():76] Current SDK version is 0.16.0
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_setup.py:_flush():76] Configure stats pid to 87874
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_setup.py:_flush():76] Loading settings from /home/biometrics/.config/wandb/settings
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_setup.py:_flush():76] Loading settings from /home/biometrics/reserve/MultimodalProduct/wandb/settings
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program_abspath': '/home/biometrics/reserve/MultimodalProduct/train.py', 'program': './train.py'}
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_init.py:_log_setup():524] Logging user logs to /home/biometrics/reserve/MultimodalProduct/work_dirs/clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji/20231114_213436/vis_data/wandb/run-20231114_213441-ua00jo79/logs/debug.log
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_init.py:_log_setup():525] Logging internal logs to /home/biometrics/reserve/MultimodalProduct/work_dirs/clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji/20231114_213436/vis_data/wandb/run-20231114_213441-ua00jo79/logs/debug-internal.log
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_init.py:init():564] calling init triggers
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {}
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_init.py:init():614] starting backend
2023-11-14 21:34:41,057 INFO    MainThread:87874 [wandb_init.py:init():618] setting up manager
2023-11-14 21:34:41,059 INFO    MainThread:87874 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-11-14 21:34:41,060 INFO    MainThread:87874 [wandb_init.py:init():624] backend started and connected
2023-11-14 21:34:41,063 INFO    MainThread:87874 [wandb_init.py:init():716] updated telemetry
2023-11-14 21:34:41,140 INFO    MainThread:87874 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2023-11-14 21:34:41,515 INFO    MainThread:87874 [wandb_run.py:_on_init():2254] communicating current version
2023-11-14 21:34:41,591 INFO    MainThread:87874 [wandb_run.py:_on_init():2263] got version response 
2023-11-14 21:34:41,591 INFO    MainThread:87874 [wandb_init.py:init():800] starting run threads in backend
2023-11-14 21:34:42,656 INFO    MainThread:87874 [wandb_run.py:_console_start():2233] atexit reg
2023-11-14 21:34:42,657 INFO    MainThread:87874 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2023-11-14 21:34:42,657 INFO    MainThread:87874 [wandb_run.py:_redirect():2153] Wrapping output streams.
2023-11-14 21:34:42,657 INFO    MainThread:87874 [wandb_run.py:_redirect():2178] Redirects installed.
2023-11-14 21:34:42,657 INFO    MainThread:87874 [wandb_init.py:init():841] run started, returning control to user process
2023-11-14 21:34:42,660 INFO    MainThread:87874 [wandb_run.py:_config_callback():1342] config_cb None None {'train_pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'color_ignore_orientation'}, {'type': 'LoadOCRAnnotations', 'with_bbox': True, 'with_polygon': True, 'with_label': True}, {'type': 'TorchVisionWrapper', 'op': 'ColorJitter', 'brightness': 0.12549019607843137, 'saturation': 0.5}, {'type': 'ImgAugWrapper', 'args': [['Fliplr', 0.5], {'cls': 'Affine', 'rotate': [-10, 10]}, ['Resize', [0.5, 3.0]]]}, {'type': 'RandomCrop', 'min_side_ratio': 0.1}, {'type': 'Resize', 'scale': [640, 640], 'keep_ratio': True}, {'type': 'Pad', 'size': [640, 640]}, {'type': 'PackTextDetInputs', 'meta_keys': ['img_path', 'ori_shape', 'img_shape']}], 'test_pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'color_ignore_orientation'}, {'type': 'Resize', 'scale': [4068, 1024], 'keep_ratio': True}, {'type': 'LoadOCRAnnotations', 'with_polygon': True, 'with_bbox': True, 'with_label': True}, {'type': 'PackTextDetInputs', 'meta_keys': ['img_path', 'ori_shape', 'img_shape', 'scale_factor']}], 'prompt_class_names': ['the pixels of many arbitrary-shape text instances.'], 'model': {'type': 'CLIPProduct', 'pretrained': 'pretrained/RN50.pt', 'context_length': 14, 'class_names': ['the pixels of many arbitrary-shape text instances.'], 'use_learnable_prompt': True, 'use_learnable_prompt_only': False, 'backbone': {'type': 'CLIPResNetWithAttention', 'layers': [3, 4, 6, 3], 'output_dim': 1024, 'input_resolution': 640, 'style': 'pytorch'}, 'text_encoder': {'type': 'CLIPTextContextEncoder', 'context_length': 18, 'embed_dim': 1024, 'transformer_width': 512, 'transformer_heads': 8, 'transformer_layers': 12, 'style': 'pytorch'}, 'prompt_generator': {'type': 'PromptGenerator', 'visual_dim': 1024, 'token_embed_dim': 512, 'style': 'pytorch'}, 'context_decoder': {'type': 'ContextDecoder', 'transformer_width': 256, 'transformer_heads': 4, 'transformer_layers': 3, 'visual_dim': 1024, 'dropout': 0.1, 'outdim': 1024, 'style': 'pytorch'}, 'visual_prompt_generator': {'type': 'ContextDecoder', 'transformer_width': 256, 'transformer_heads': 4, 'transformer_layers': 3, 'visual_dim': 1024, 'dropout': 0.1, 'outdim': 1024, 'style': 'pytorch'}, 'neck': {'type': 'FPNC', 'in_channels': [256, 512, 1024, 2049], 'lateral_channels': 256}, 'det_head': {'type': 'DBHead', 'in_channels': 256, 'module_loss': {'type': 'DBModuleLoss'}, 'postprocessor': {'type': 'DBPostprocessor', 'text_repr_type': 'quad'}}, 'identity_head': {'type': 'IdentityHead', 'downsample_ratio': 32.0, 'loss_weight': 1.0, 'reduction': 'mean', 'negative_ratio': 3.0, 'bbce_loss': True}, 'data_preprocessor': {'type': 'TextDetDataPreprocessor', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'bgr_to_rgb': True, 'pad_size_divisor': 32}}, 'icdar2015_textdet_data_root': 'data/icdar2015', 'icdar2015_textdet_train': {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textdet_train.json', 'filter_cfg': {'filter_empty_gt': True, 'min_size': 32}, 'pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'color_ignore_orientation'}, {'type': 'LoadOCRAnnotations', 'with_bbox': True, 'with_polygon': True, 'with_label': True}, {'type': 'TorchVisionWrapper', 'op': 'ColorJitter', 'brightness': 0.12549019607843137, 'saturation': 0.5}, {'type': 'ImgAugWrapper', 'args': [['Fliplr', 0.5], {'cls': 'Affine', 'rotate': [-10, 10]}, ['Resize', [0.5, 3.0]]]}, {'type': 'RandomCrop', 'min_side_ratio': 0.1}, {'type': 'Resize', 'scale': [640, 640], 'keep_ratio': True}, {'type': 'Pad', 'size': [640, 640]}, {'type': 'PackTextDetInputs', 'meta_keys': ['img_path', 'ori_shape', 'img_shape']}]}, 'icdar2015_textdet_test': {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textdet_test.json', 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'color_ignore_orientation'}, {'type': 'Resize', 'scale': [4068, 1024], 'keep_ratio': True}, {'type': 'LoadOCRAnnotations', 'with_polygon': True, 'with_bbox': True, 'with_label': True}, {'type': 'PackTextDetInputs', 'meta_keys': ['img_path', 'ori_shape', 'img_shape', 'scale_factor']}]}, 'default_scope': 'mmocr', 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'randomness': {'seed': None}, 'default_hooks': {'timer': {'type': 'IterTimerHook'}, 'logger': {'type': 'LoggerHook', 'interval': 5}, 'param_scheduler': {'type': 'ParamSchedulerHook'}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 5, 'max_keep_ckpts': 1}, 'sampler_seed': {'type': 'DistSamplerSeedHook'}, 'sync_buffer': {'type': 'SyncBuffersHook'}, 'visualization': {'type': 'VisualizationHook', 'interval': 1, 'enable': False, 'show': False, 'draw_gt': False, 'draw_pred': False}}, 'log_level': 'INFO', 'log_processor': {'type': 'LogProcessor', 'window_size': 10, 'by_epoch': True}, 'load_from': None, 'resume': False, 'val_evaluator': {'type': 'HmeanIOUMetric'}, 'test_evaluator': {'type': 'HmeanIOUMetric'}, 'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'WandbVisBackend'}], 'visualizer': {'type': 'TextDetLocalVisualizer', 'name': 'visualizer', 'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'WandbVisBackend'}]}, 'optim_wrapper': {'type': 'OptimWrapper', 'optimizer': {'type': 'SGD', 'lr': 0.007, 'momentum': 0.9, 'weight_decay': 0.0001}}, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 1200, 'val_interval': 20}, 'val_cfg': {'type': 'ValLoop'}, 'test_cfg': {'type': 'TestLoop'}, 'param_scheduler': [{'type': 'PolyLR', 'power': 0.9, 'eta_min': 1e-07, 'begin': 100, 'end': 1200}], 'train_dataloader': {'batch_size': 16, 'num_workers': 24, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': True}, 'dataset': {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textdet_train.json', 'filter_cfg': {'filter_empty_gt': True, 'min_size': 32}, 'pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'color_ignore_orientation'}, {'type': 'LoadOCRAnnotations', 'with_bbox': True, 'with_polygon': True, 'with_label': True}, {'type': 'TorchVisionWrapper', 'op': 'ColorJitter', 'brightness': 0.12549019607843137, 'saturation': 0.5}, {'type': 'ImgAugWrapper', 'args': [['Fliplr', 0.5], {'cls': 'Affine', 'rotate': [-10, 10]}, ['Resize', [0.5, 3.0]]]}, {'type': 'RandomCrop', 'min_side_ratio': 0.1}, {'type': 'Resize', 'scale': [640, 640], 'keep_ratio': True}, {'type': 'Pad', 'size': [640, 640]}, {'type': 'PackTextDetInputs', 'meta_keys': ['img_path', 'ori_shape', 'img_shape']}]}}, 'val_dataloader': {'batch_size': 1, 'num_workers': 4, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textdet_test.json', 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'color_ignore_orientation'}, {'type': 'Resize', 'scale': [4068, 1024], 'keep_ratio': True}, {'type': 'LoadOCRAnnotations', 'with_polygon': True, 'with_bbox': True, 'with_label': True}, {'type': 'PackTextDetInputs', 'meta_keys': ['img_path', 'ori_shape', 'img_shape', 'scale_factor']}]}}, 'test_dataloader': {'batch_size': 1, 'num_workers': 4, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textdet_test.json', 'test_mode': True, 'pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'color_ignore_orientation'}, {'type': 'Resize', 'scale': [4068, 1024], 'keep_ratio': True}, {'type': 'LoadOCRAnnotations', 'with_polygon': True, 'with_bbox': True, 'with_label': True}, {'type': 'PackTextDetInputs', 'meta_keys': ['img_path', 'ori_shape', 'img_shape', 'scale_factor']}]}}, 'auto_scale_lr': {'base_batch_size': 16}, 'launcher': 'pytorch', 'work_dir': './work_dirs/clip_db_r50_fpnc_prompt_gen_vis_1200e_ft_gen_ic15_adam_taiji'}
2023-11-15 10:00:22,673 WARNING MsgRouterThr:87874 [router.py:message_loop():77] message_loop has been closed
